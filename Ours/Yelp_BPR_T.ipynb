{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fNaE73RP23kP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "import multiprocessing as mp\n",
        "import argparse\n",
        "\n",
        "import math\n",
        "import heapq # for retrieval topK\n",
        "\n",
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "from tqdm import tqdm  # tqdm 라이브러리 임포트\n",
        "from tqdm.auto import trange\n",
        "import random\n",
        "from multiprocessing import Pool\n",
        "import _multiprocessing\n",
        "import pickle\n",
        "from scipy.spatial.distance import pdist, squareform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5klGMkPE28sE"
      },
      "outputs": [],
      "source": [
        "def get_data(path = 'dataset/'):\n",
        "    # 위도 경도 load\n",
        "    business_info_file = path + 'business_info.csv' # 필라델피아 가게 정보 business_id, latitude, longitude, city, idx\n",
        "    \n",
        "    business_location = []\n",
        "    with open(business_info_file, 'r', newline='') as business_file:\n",
        "        csv_reader = csv.reader(business_file)\n",
        "        next(csv_reader)  # 헤더 행 건너뛰기\n",
        "        for row in csv_reader:\n",
        "            _, latitude, longitude, _, _ = row[0], row[1], row[2], row[3].lower(), row[4] #city : 소문자로 받음\n",
        "\n",
        "            business_location.append([latitude, longitude])\n",
        "    business_location = np.array(business_location, dtype=float)\n",
        "\n",
        "    # 리뷰 load\n",
        "    input_file = path + \"reviews.txt\"\n",
        "    data = []\n",
        "    with open(input_file, 'r', newline='', encoding='utf-8') as csv_file:\n",
        "        csv_reader = csv.reader(csv_file)\n",
        "        for row in csv_reader:\n",
        "            data.append(row)\n",
        "\n",
        "    if not data:  # 데이터가 비어있는 경우 처리\n",
        "        return\n",
        "\n",
        "    user_history_list = []\n",
        "    user_reviews_list = []\n",
        "    user_ratings_list = []\n",
        "    user_review_emb_list = []\n",
        "\n",
        "    tmp_reviews = []\n",
        "    tmp_ratings = []\n",
        "    tmp_business_id = []\n",
        "    tmp_review_emb_list = []\n",
        "\n",
        "    before_user_id = data[0][0]  # 첫 번째 사용자 ID로 초기화\n",
        "    for idx, i in enumerate(data):\n",
        "        user_id, business_id, rating, review = i\n",
        "        if user_id == before_user_id:\n",
        "            tmp_business_id.append(int(business_id))\n",
        "            tmp_ratings.append(float(rating))\n",
        "            tmp_reviews.append(review)\n",
        "            tmp_review_emb_list.append(idx)\n",
        "        else:\n",
        "            if len(tmp_business_id) >= 10:  # 방문 횟수가 10회가 넘는 유저만 append\n",
        "                user_history_list.append(tmp_business_id)\n",
        "                user_ratings_list.append(tmp_ratings)\n",
        "                user_reviews_list.append(tmp_reviews)\n",
        "                user_review_emb_list.append(tmp_review_emb_list)\n",
        "            tmp_business_id = [int(business_id)]\n",
        "            tmp_ratings = [float(rating)]\n",
        "            tmp_reviews = [review]\n",
        "            tmp_review_emb_list = [idx]\n",
        "\n",
        "            before_user_id = user_id  # 현재 사용자 ID로 업데이트\n",
        "\n",
        "    # 마지막 사용자 처리\n",
        "    if len(tmp_business_id) >= 10:\n",
        "        user_history_list.append(tmp_business_id)\n",
        "        user_ratings_list.append(tmp_ratings)\n",
        "        user_reviews_list.append(tmp_reviews)\n",
        "        user_review_emb_list.append(tmp_review_emb_list)\n",
        "    print(len(user_history_list), len(user_ratings_list), len(user_reviews_list), len(user_review_emb_list))\n",
        "\n",
        "\n",
        "    # POI가 가진 리뷰 임베딩을 획득하기 위해\n",
        "    # history_list를 기준으로 POI에 방문한 사람들 list 생성\n",
        "    poi_visited_list = []\n",
        "    for user,history in enumerate(user_history_list):\n",
        "        for idx, poi in enumerate(history):\n",
        "            poi_visited_list.append([int(user), int(poi), float(user_ratings_list[user][idx]), user_reviews_list[user][idx], user_review_emb_list[user][idx]])\n",
        "\n",
        "    poi_visited_list.sort(key = lambda x:x[1]) # poi 번호 순으로 정렬\n",
        "\n",
        "    item_history_list = []\n",
        "    item_reviews_list = []\n",
        "    item_ratings_list = []\n",
        "    item_review_emb_list = []\n",
        "\n",
        "\n",
        "    tmp_reviews = []\n",
        "    tmp_ratings = []\n",
        "    tmp_user_id = []\n",
        "    tmp_review_emb = []\n",
        "    before_poi_id = poi_visited_list[0][1]  # 첫 번째 POI ID로 초기화\n",
        "\n",
        "    for idx, i in enumerate(poi_visited_list):\n",
        "        user_id, business_id, rating, review, review_emb = i[0], i[1], i[2], i[3], i[4]\n",
        "        if business_id == before_poi_id: # 이전 POI Id와 동일하다면\n",
        "            tmp_user_id.append(user_id)\n",
        "            tmp_ratings.append(rating)\n",
        "            tmp_reviews.append(review)\n",
        "            tmp_review_emb.append(review_emb)\n",
        "        else: # 이전 POI ID와 다른 POI라면\n",
        "            #print(business_id)\n",
        "            # 이전 POI 정보 안에 있던거 다 추가하고\n",
        "            item_history_list.append(tmp_user_id)\n",
        "            item_ratings_list.append(tmp_ratings)\n",
        "            item_reviews_list.append(tmp_reviews)\n",
        "            item_review_emb_list.append(tmp_review_emb)\n",
        "\n",
        "            if int(business_id) - int(before_poi_id) > 1:\n",
        "                for _ in range(int(business_id) - int(before_poi_id) - 1):\n",
        "                    #print(f\"방문 기록이 없는 POI는 PASS\")\n",
        "                    item_history_list.append([])\n",
        "                    item_ratings_list.append([])\n",
        "                    item_reviews_list.append([])\n",
        "                    item_review_emb_list.append([])\n",
        "\n",
        "            tmp_user_id = [user_id]\n",
        "            tmp_ratings = [rating]\n",
        "            tmp_reviews = [review]\n",
        "            tmp_review_emb = [review_emb]\n",
        "\n",
        "            before_poi_id = business_id  # 현재 사용자 ID로 업데이트\n",
        "\n",
        "    item_history_list.append(tmp_business_id)\n",
        "    item_ratings_list.append(tmp_ratings)\n",
        "    item_reviews_list.append(tmp_reviews)\n",
        "    item_review_emb_list.append(tmp_review_emb)\n",
        "\n",
        "    print(len(item_history_list), len(item_ratings_list), len(item_reviews_list), len(item_review_emb_list))\n",
        "\n",
        "    # 임베딩 load\n",
        "    embedding_file = path + 'embeddings.npy'\n",
        "    embeddings = np.load(embedding_file, mmap_mode='r')\n",
        "\n",
        "    user_review_embs = []\n",
        "    for poi, embeds in enumerate(user_review_emb_list):\n",
        "        if len(embeds)>0: # 비어있지 않으면\n",
        "            new_array = np.array([embeddings[idx] for idx in embeds])\n",
        "            new_array = np.mean(new_array, axis = 0)\n",
        "        else:\n",
        "            new_array = np.zeros(768, dtype=np.float32)\n",
        "        user_review_embs.append(new_array)\n",
        "\n",
        "    item_review_embs = []\n",
        "    for poi, embeds in enumerate(item_review_emb_list):\n",
        "        if len(embeds)>0: # 비어있지 않으면\n",
        "            new_array = np.array([embeddings[idx] for idx in embeds])\n",
        "            new_array = np.mean(new_array, axis = 0)\n",
        "        else:\n",
        "            new_array = np.zeros(768, dtype=np.float32)\n",
        "\n",
        "        item_review_embs.append(new_array.tolist())\n",
        "\n",
        "    return user_history_list, user_ratings_list, user_reviews_list, user_review_embs, item_history_list, item_ratings_list, item_reviews_list, item_review_embs, business_location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m6qRtumj3FXu"
      },
      "outputs": [],
      "source": [
        "class Yelp(Dataset):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Yelp 데이터셋을 로드하고 학습 데이터와 테스트 데이터를 생성합니다.\n",
        "\n",
        "        Args:\n",
        "            dir (str): 데이터 파일이 있는 디렉토리 경로.\n",
        "            splitter (str): 파일에서 열을 구분하는 구분자.\n",
        "            K (int): K 값, 즉 각 사용자마다 테스트에 사용되는 상호작용의 수.\n",
        "        \"\"\"\n",
        "        path = 'dataset/'\n",
        "        user_history_list, _, _, user_review_embeds ,_,_,_,poi_review_embeds = get_data(path)\n",
        "\n",
        "        self.train = []\n",
        "        self.test = []\n",
        "        self.poi_review_embeds = torch.tensor(poi_review_embeds).to(DEVICE)\n",
        "        self.user_review_embeds = torch.tensor(user_review_embeds).to(DEVICE)\n",
        "        self.num_user = len(user_history_list)\n",
        "        self.num_item = len(poi_review_embeds) # 14585\n",
        "\n",
        "        items = [i for i in range(self.num_item)]\n",
        "        self.neg = dict()\n",
        "\n",
        "        random.seed(30)\n",
        "        for u, hist in enumerate(user_history_list):\n",
        "            random.shuffle(hist)\n",
        "            self.train.append(hist[:int(len(hist) * 0.7)])\n",
        "            self.test.append(hist[int(len(hist) * 0.7) :])\n",
        "\n",
        "            u_negs = set(items) - set(hist)\n",
        "            self.neg[u] = list(u_negs) # ng dataset 생성\n",
        "\n",
        "        # self.test_for_eval = []\n",
        "        # for u,hist in enumerate(self.test):\n",
        "        #     for i in hist:\n",
        "        #         self.test_for_eval.append([u,i])\n",
        "\n",
        "        self.index_map = []\n",
        "        for u, user_items in enumerate(self.train):\n",
        "            for i in user_items:\n",
        "                self.index_map.append((u, i))\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        데이터셋의 사용자 수를 반환합니다.\n",
        "        \"\"\"\n",
        "        #return self.num_user\n",
        "        return len(self.index_map)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        데이터셋에서 하나의 샘플을 가져옵니다.\n",
        "\n",
        "        Args:\n",
        "            idx (int): 데이터셋 내의 인덱스.\n",
        "\n",
        "        Returns:\n",
        "            u: 사용자 ID.\n",
        "            i: 긍정적인 아이템 ID.\n",
        "            j: 부정적인 아이템 ID.\n",
        "        \"\"\"\n",
        "        # u = idx\n",
        "        # # 사용자별로 하나의 긍정적인 상호작용 선택\n",
        "        # i = self.train[u][np.random.randint(0, len(self.train[u]))]\n",
        "        # # 부정적인 상호작용 무작위 선택\n",
        "        # j = self.neg[u][np.random.randint(0, len(self.neg[u]))]\n",
        "        # #j = random.sample(self.neg[u], 4)\n",
        "        # return (u, i, j)\n",
        "\n",
        "        u, i = self.index_map[idx]\n",
        "        # 부정적인 아이템 무작위 선택\n",
        "        j = self.neg[u][np.random.randint(0, len(self.neg[u]))]\n",
        "        return (u, i, j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Jk9LEkZ6UD90"
      },
      "outputs": [],
      "source": [
        "class MFbpr(nn.Module):\n",
        "    '''\n",
        "    MF 모델에 대한 BPR 학습\n",
        "    '''\n",
        "    def __init__(self, dataset, factors, learning_rate, reg, init_mean, init_stdev):\n",
        "        '''\n",
        "        생성자\n",
        "        Args:\n",
        "            dataset: 데이터셋 객체로, 학습 및 테스트 데이터를 포함합니다.\n",
        "            factors (int): 잠재 요인의 수.\n",
        "            learning_rate (float): 최적화에 사용되는 학습률.\n",
        "            reg (float): 정규화 강도.\n",
        "            init_mean (float): 초기화에 사용되는 정규 분포의 평균.\n",
        "            init_stdev (float): 초기화에 사용되는 정규 분포의 표준 편차.\n",
        "        '''\n",
        "        super(MFbpr, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.train_data = dataset.train\n",
        "        self.test_data = dataset.test\n",
        "        self.num_user = dataset.num_user\n",
        "        self.num_item = dataset.num_item\n",
        "        self.neg = dataset.neg\n",
        "        self.factors = factors\n",
        "        self.learning_rate = learning_rate\n",
        "        self.reg = reg\n",
        "        self.init_mean = init_mean\n",
        "        self.init_stdev = init_stdev\n",
        "\n",
        "\n",
        "        # 사용자와 아이템의 잠재 요인을 초기화합니다.\n",
        "        self.embed_user = torch.normal(mean=self.init_mean * torch.ones(self.num_user, self.factors), std=self.init_stdev).to(DEVICE).requires_grad_()\n",
        "        self.embed_item = torch.normal(mean=self.init_mean * torch.ones(self.num_item, self.factors), std=self.init_stdev).to(DEVICE).requires_grad_()\n",
        "\n",
        "        # Adam optimizer를 초기화합니다.\n",
        "        self.mf_optim = optim.Adam([self.embed_user, self.embed_item], lr=self.learning_rate)\n",
        "\n",
        "    def forward(self, u, i, j):\n",
        "        '''\n",
        "        MF-BPR 모델의 forward pass입니다.\n",
        "        Args:\n",
        "            u: 사용자 ID.\n",
        "            i: 긍정적인 아이템 ID.\n",
        "            j: 부정적인 아이템 ID.\n",
        "        Returns:\n",
        "            y_ui: 사용자와 긍정적인 아이템 간의 예측 점수.\n",
        "            y_uj: 사용자와 부정적인 아이템 간의 예측 점수.\n",
        "            loss: BPR 손실.\n",
        "        '''\n",
        "        # 사용자와 긍정적인 아이템 간의 예측 점수 계산\n",
        "        y_ui = (self.embed_user[u] * self.embed_item[i]).sum(dim=-1)\n",
        "        # 사용자와 부정적인 아이템 간의 예측 점수 계산\n",
        "        y_uj = (self.embed_user[u] * self.embed_item[j]).sum(dim=-1)\n",
        "        # 정규화 항 계산\n",
        "        regularizer = self.reg * (torch.sum(self.embed_user[u] ** 2) + torch.sum(self.embed_item[i] ** 2) + torch.sum(self.embed_item[j] ** 2))\n",
        "        # BPR 손실 계산\n",
        "        loss = regularizer - torch.sum(torch.log(torch.sigmoid(y_ui - y_uj)))\n",
        "        return y_ui, y_uj, loss\n",
        "\n",
        "    def build_model(self, epoch=30, batch_size=32, topK = 10):\n",
        "        '''\n",
        "        MF-BPR 모델을 구축하고 학습합니다.\n",
        "        Args:\n",
        "            epoch (int): 학습의 최대 반복 횟수.\n",
        "            num_thread (int): 병렬 실행을 위한 스레드 수.\n",
        "            batch_size (int): 학습용 배치 크기.\n",
        "        '''\n",
        "        data_loader = DataLoader(self.dataset, batch_size=batch_size)\n",
        "\n",
        "        print(\"Training MF-BPR with: learning_rate=%.4f, regularization=%.7f, factors=%d, #epoch=%d, batch_size=%d.\"\n",
        "               % (self.learning_rate, self.reg, self.factors, epoch, batch_size))\n",
        "        t1 = time.time()\n",
        "\n",
        "        max_hit, max_precision, max_recall, max_recall_epoch, max_precision_epoch, max_hit_epoch = 0,0,0,0,0,0\n",
        "        for epoc in range(epoch):\n",
        "            iter_loss = 0\n",
        "            for s, (users, items_pos, items_neg) in enumerate(data_loader):\n",
        "                # 기울기 초기화\n",
        "                self.mf_optim.zero_grad()\n",
        "                # Forward pass를 통해 예측과 손실 계산\n",
        "                y_ui, y_uj, loss = self.forward(users, items_pos, items_neg)\n",
        "                iter_loss += loss\n",
        "                # Backward pass 및 파라미터 업데이트\n",
        "                loss.backward()\n",
        "                self.mf_optim.step()\n",
        "            t2 = time.time()\n",
        "\n",
        "            # 성능 측정 함수를 통해 HitRatio 및 NDCG를 계산\n",
        "\n",
        "            hits, recall, precision = self.evaluate_model(self.test_data, topK)\n",
        "\n",
        "            print(f\"epoch={epoc}, loss = {iter_loss}[{int(t2-t1)}s] HitRatio@{topK} = {hits}, RECAll@{topK} = {recall}, PRECISION@{topK} = {precision} [{int(time.time()-t2)}s]\")\n",
        "            t1 = time.time()\n",
        "            if precision > max_precision:\n",
        "                max_precision = precision\n",
        "                max_precision_epoch = epoc\n",
        "            if recall > max_recall:\n",
        "                max_recall = recall\n",
        "                max_recall_epoch = epoc\n",
        "            if hits > max_hit:\n",
        "                max_hit = hits\n",
        "                max_hit_epoch = epoc\n",
        "            t1 = time.time()\n",
        "\n",
        "        #save_perform(reg, batch_size, latent_factors, text_factors, epoc, learning_rate, max_hit, max_hit_epoch, max_recall, max_recall_epoch, max_precision, max_precision_epoch)\n",
        "\n",
        "\n",
        "    def evaluate_model(self, test, K):\n",
        "        \"\"\"\n",
        "        Top-K 추천의 성능(Hit_Ratio, NDCG)을 평가합니다.\n",
        "        반환값: 각 테스트 상호작용의 점수.\n",
        "        \"\"\"\n",
        "        score_matrix = torch.mm(self.embed_user, self.embed_item.t())\n",
        "        top_scores, top_indicies = torch.topk(score_matrix, K, dim=1)\n",
        "\n",
        "        hits = 0\n",
        "        sum_recall = 0\n",
        "        sum_precision = 0\n",
        "        for u,hist in enumerate(test):\n",
        "            set_topk = set(i.item() for i in (top_indicies[u]))\n",
        "            set_hist = set(hist)\n",
        "\n",
        "            if set_hist & set_topk:\n",
        "                hits += 1\n",
        "            sum_precision += len(set_hist & set_topk) / len(set_topk)\n",
        "            sum_recall += len(set_hist & set_topk) / len(set_hist)\n",
        "\n",
        "        return hits / len(test), sum_recall / len(test), sum_precision / len(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iU55gpzKbQVq"
      },
      "outputs": [],
      "source": [
        "class TextBPR(nn.Module):\n",
        "    '''\n",
        "    MF 모델에 대한 BPR 학습\n",
        "    '''\n",
        "    def __init__(self, dataset, factors, text_factors, learning_rate, reg, init_mean, init_stdev, alpha):\n",
        "        '''\n",
        "        생성자\n",
        "        Args:\n",
        "            dataset: 데이터셋 객체로, 학습 및 테스트 데이터를 포함합니다.\n",
        "            factors (int): 잠재 요인의 수.\n",
        "            learning_rate (float): 최적화에 사용되는 학습률.\n",
        "            reg (float): 정규화 강도.\n",
        "            init_mean (float): 초기화에 사용되는 정규 분포의 평균.\n",
        "            init_stdev (float): 초기화에 사용되는 정규 분포의 표준 편차.\n",
        "        '''\n",
        "        super(TextBPR, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.train_data = dataset.train\n",
        "        self.test_data = dataset.test\n",
        "        # self.test_for_eval = dataset.test_for_eval\n",
        "        self.num_user = dataset.num_user\n",
        "        self.num_item = dataset.num_item\n",
        "        self.neg = dataset.neg\n",
        "        self.factors = factors\n",
        "        self.factors_Text = text_factors\n",
        "        self.learning_rate = learning_rate\n",
        "        self.reg = reg\n",
        "        self.init_mean = init_mean\n",
        "        self.init_stdev = init_stdev\n",
        "        # self.alpha = alpha\n",
        "        self.alpha = nn.Parameter(torch.tensor(alpha)).to(DEVICE).requires_grad_()\n",
        "\n",
        "        self.user_review_embeds = dataset.user_review_embeds.to(DEVICE)\n",
        "        self.poi_review_embeds = dataset.poi_review_embeds.to(DEVICE)\n",
        "\n",
        "        # 사용자와 아이템의 잠재 요인을 초기화합니다.\n",
        "        self.embed_user = torch.normal(mean=self.init_mean * torch.ones(self.num_user, self.factors), std=self.init_stdev).to(DEVICE).requires_grad_()\n",
        "        self.embed_item = torch.normal(mean=self.init_mean * torch.ones(self.num_item, self.factors), std=self.init_stdev).to(DEVICE).requires_grad_()\n",
        "\n",
        "        self.beta_items = torch.normal(mean=self.init_mean * torch.ones(self.num_item, 1), std=self.init_stdev).to(DEVICE).requires_grad_()\n",
        "        self.text_bias = torch.normal(mean=self.init_mean * torch.ones(768, 1), std=self.init_stdev).to(DEVICE).requires_grad_()\n",
        "\n",
        "        # Adam optimizer를 초기화합니다.\n",
        "        self.mf_optim = optim.Adam([self.embed_user, self.embed_item, self.beta_items, self.text_bias], lr=self.learning_rate, weight_decay=1e-5)\n",
        "\n",
        "    def forward(self, u, i, j):\n",
        "        '''\n",
        "        MF-BPR 모델의 forward pass입니다.\n",
        "        Args:\n",
        "            u: 사용자 ID.\n",
        "            i: 긍정적인 아이템 ID.\n",
        "            j: 부정적인 아이템 ID.\n",
        "        Returns:\n",
        "            y_ui: 사용자와 긍정적인 아이템 간의 예측 점수.\n",
        "            y_uj: 사용자와 부정적인 아이템 간의 예측 점수.\n",
        "            loss: BPR 손실.\n",
        "        '''\n",
        "        # 사용자와 긍정적인 아이템 간의 예측 점수 계산\n",
        "\n",
        "        user_latent_factor = self.embed_user[u]\n",
        "        user_text_factors = self.user_review_embeds[u] / math.sqrt(786)\n",
        "        alpha = self.alpha\n",
        "\n",
        "\n",
        "        i_bias = self.beta_items[i] # batch * 1\n",
        "        j_bias = self.beta_items[j] # batch * 1\n",
        "\n",
        "        i_text_factors = self.poi_review_embeds[i] # batch * 768\n",
        "        j_text_factors = self.poi_review_embeds[j] # batch * 768\n",
        "\n",
        "        i_latent_factors = self.embed_item[i]\n",
        "        j_latent_factors = self.embed_item[j]\n",
        "\n",
        "        diff_latent_factors = i_latent_factors - j_latent_factors # batch * latent\n",
        "        diff_text_factors = (i_text_factors - j_text_factors) / math.sqrt(768) # batch * 768\n",
        "\n",
        "        if diff_text_factors.shape[0] == 768: # [768], eval set이라면\n",
        "            user_latent_factor = user_latent_factor.unsqueeze(0)\n",
        "            user_text_factors = user_text_factors.unsqueeze(0)\n",
        "            diff_text_factors = diff_text_factors.unsqueeze(0) # [1, text_emb]\n",
        "            diff_latent_factors = diff_latent_factors.unsqueeze(0) # [ 1, latent_emb]\n",
        "\n",
        "        latent_factor = (user_latent_factor * diff_latent_factors).sum(dim=-1).unsqueeze(-1)\n",
        "        text_factor = (user_text_factors * diff_text_factors).sum(dim=-1).unsqueeze(-1)\n",
        "\n",
        "        u_i_score = alpha * latent_factor + (1 - alpha) * text_factor\n",
        "        text_bias = diff_text_factors.mm(self.text_bias)\n",
        "\n",
        "        x_uij = i_bias - j_bias + u_i_score + text_bias\n",
        "\n",
        "        # 정규화 항 계산\n",
        "        # BPR 손실 계산\n",
        "        loss = -torch.sum(torch.log(torch.sigmoid(x_uij.unsqueeze(0))))\n",
        "        return loss\n",
        "\n",
        "    def build_model(self, epoch=30, batch_size=32, topK = 10):\n",
        "        '''\n",
        "        MF-BPR 모델을 구축하고 학습합니다.\n",
        "        Args:\n",
        "            epoch (int): 학습의 최대 반복 횟수.\n",
        "            num_thread (int): 병렬 실행을 위한 스레드 수.\n",
        "            batch_size (int): 학습용 배치 크기.\n",
        "        '''\n",
        "        data_loader = DataLoader(self.dataset, batch_size=batch_size)\n",
        "\n",
        "        print(\"Training MF-BPR with: learning_rate=%.4f, regularization=%.7f, factors=%d, #epoch=%d, batch_size=%d.\"\n",
        "               % (self.learning_rate, self.reg, self.factors, epoch, batch_size))\n",
        "        t1 = time.time()\n",
        "\n",
        "        max_hit, max_precision, max_recall, max_recall_epoch, max_precision_epoch, max_hit_epoch = 0,0,0,0,0,0\n",
        "        for epoc in range(epoch):\n",
        "            iter_loss = 0\n",
        "            count = 0\n",
        "            for s, (users, items_pos, items_neg) in enumerate(data_loader):\n",
        "                users = users.to(DEVICE)\n",
        "                items_pos = items_pos.to(DEVICE)\n",
        "                items_neg = items_neg.to(DEVICE)\n",
        "\n",
        "                count += 1\n",
        "                # 기울기 초기화\n",
        "                self.mf_optim.zero_grad()\n",
        "                # Forward pass를 통해 예측과 손실 계산\n",
        "                loss = self.forward(users, items_pos, items_neg)\n",
        "                iter_loss += loss\n",
        "                # Backward pass 및 파라미터 업데이트\n",
        "                loss.backward()\n",
        "                self.mf_optim.step()\n",
        "            t2 = time.time()\n",
        "\n",
        "            # 성능 측정 함수를 통해 HitRatio 및 NDCG를 계산\n",
        "            hits, recall, precision = self.evaluate_model(self.test_data, topK)\n",
        "            # eval_loss = 0\n",
        "            # for idx, (u, i, j) in enumerate(self.test_for_eval):\n",
        "            #     u, i, j = u.to(DEVICE), i.to(DEVICE), j.to(DEVICE)\n",
        "            #     loss = self.forward(u, i, j)\n",
        "            #     eval_loss += loss\n",
        "            # total_samples = len(self.test_for_eval)\n",
        "            # eval_loss = eval_loss / total_samples if total_samples > 0 else 0\n",
        "            # iter_loss = iter_loss / count / batch_size\n",
        "            print(f\"epoch={epoc}, train_loss = {iter_loss:.6} [{int(t2-t1)}s] HitRatio@{topK} = {hits:.6}, RECAll@{topK} = {recall:.6}, PRECISION@{topK} = {precision:.6} [{int(time.time()-t2)}s], alpha: {alpha}\")\n",
        "            t1 = time.time()\n",
        "            if precision > max_precision:\n",
        "                max_precision = precision\n",
        "                max_precision_epoch = epoc\n",
        "            if recall > max_recall:\n",
        "                max_recall = recall\n",
        "                max_recall_epoch = epoc\n",
        "            if hits > max_hit:\n",
        "                max_hit = hits\n",
        "                max_hit_epoch = epoc\n",
        "            t1 = time.time()\n",
        "\n",
        "        #save_perform(reg, batch_size, latent_factors, text_factors, epoc, learning_rate, max_hit, max_hit_epoch, max_recall, max_recall_epoch, max_precision, max_precision_epoch, alpha)\n",
        "\n",
        "\n",
        "    def evaluate_model(self, test, K):\n",
        "        \"\"\"\n",
        "        Top-K 추천의 성능(Hit_Ratio, NDCG)을 평가합니다.\n",
        "        반환값: 각 테스트 상호작용의 점수.\n",
        "        \"\"\"\n",
        "        user_latent_factor = self.embed_user # batch * latent\n",
        "        item_latent_factors = self.embed_item # batch * latent\n",
        "\n",
        "        user_text_factors = self.user_review_embeds / math.sqrt(768) # batch * latent\n",
        "        item_text_factors = self.poi_review_embeds / math.sqrt(768)# batch * 768\n",
        "\n",
        "\n",
        "        latent_score_matrix = torch.mm(user_latent_factor, item_latent_factors.t())\n",
        "        text_score_matrix = torch.mm(user_text_factors, item_text_factors.t())\n",
        "\n",
        "        score_matrix = self.alpha * latent_score_matrix + (1-self.alpha) * text_score_matrix\n",
        "\n",
        "        item_bias = self.beta_items.squeeze()\n",
        "        item_bias = item_bias.view(1, -1)\n",
        "        score_matrix = score_matrix + item_bias\n",
        "\n",
        "\n",
        "        top_scores, top_indicies = torch.topk(score_matrix, K, dim=1)\n",
        "\n",
        "        hits = 0\n",
        "        sum_recall = 0\n",
        "        sum_precision = 0\n",
        "        for u,hist in enumerate(test):\n",
        "            set_topk = set(i.item() for i in (top_indicies[u]))\n",
        "            set_hist = set(hist)\n",
        "\n",
        "            if set_hist & set_topk:\n",
        "                hits += 1\n",
        "            sum_precision += len(set_hist & set_topk) / len(set_topk)\n",
        "            sum_recall += len(set_hist & set_topk) / len(set_hist)\n",
        "\n",
        "        return hits / len(test), sum_recall / len(test), sum_precision / len(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qBEb-Lu8jwKe"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xF-neqBr-J_k"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30)\n",
        "yelp = Yelp()\n",
        "# with open('/content/drive/MyDrive/학교/졸업작품/yelp.pkl', 'wb') as f:\n",
        "#     pickle.dump(yelp, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hX63rKoAy65K"
      },
      "outputs": [],
      "source": [
        "# with open('/content/drive/MyDrive/학교/졸업작품/yelp.pkl', 'rb') as f:\n",
        "#     yelp = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voOnkC-JdAKe",
        "outputId": "a19eabdc-2424-495e-f14a-c6aa04f9ba98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "319337"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 개선 한 유저당 n개의 긍정, 부정 데이터셋(n = 방문한 모든 POI)\n",
        "len(yelp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ip0jc-bvwS7q",
        "outputId": "17a1b63a-ec5c-4077-c0ce-3ffabf949ce6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "thread num:  12\n",
            "#factors: 768, lr: 0.000500, reg: 0.000100, batch_size: 1024\n",
            "Training MF-BPR with: learning_rate=0.0005, regularization=0.0001000, factors=768, #epoch=100, batch_size=1024.\n",
            "epoch=0, loss = 221348.671875[4e+00s] HitRatio@10 = 0.19575456886265152, RECAll@10 = 0.032288273353077344, PRECISION@10 = 0.02319286566601819 [2e+00s]\n",
            "epoch=1, loss = 212598.328125[4e+00s] HitRatio@10 = 0.22049864975193118, RECAll@10 = 0.035505931570072695, PRECISION@10 = 0.02809772027884306 [2e+00s]\n",
            "epoch=2, loss = 151832.546875[4e+00s] HitRatio@10 = 0.22087546316648873, RECAll@10 = 0.03547939871918259, PRECISION@10 = 0.028009797148779617 [2e+00s]\n",
            "epoch=3, loss = 102255.453125[4e+00s] HitRatio@10 = 0.2301073918231489, RECAll@10 = 0.03718448763473138, PRECISION@10 = 0.029247001193243725 [2e+00s]\n",
            "epoch=4, loss = 89560.328125[6e+00s] HitRatio@10 = 0.23789486905733845, RECAll@10 = 0.03880752950596642, PRECISION@10 = 0.0305721283677712 [2e+00s]\n",
            "epoch=5, loss = 81207.6875[4e+00s] HitRatio@10 = 0.249073667022546, RECAll@10 = 0.04115327002410016, PRECISION@10 = 0.03208566224957759 [2e+00s]\n",
            "epoch=6, loss = 74618.53125[4e+00s] HitRatio@10 = 0.2610688940526283, RECAll@10 = 0.04359259333973914, PRECISION@10 = 0.03405137222885316 [2e+00s]\n",
            "epoch=7, loss = 67867.3671875[4e+00s] HitRatio@10 = 0.2725617031966338, RECAll@10 = 0.04569830445253308, PRECISION@10 = 0.03570307102933073 [2e+00s]\n",
            "epoch=8, loss = 61339.125[4e+00s] HitRatio@10 = 0.2789675312441123, RECAll@10 = 0.04697356714252469, PRECISION@10 = 0.036594862777117126 [2e+00s]\n",
            "epoch=9, loss = 55216.5078125[6e+00s] HitRatio@10 = 0.28763423977893615, RECAll@10 = 0.04910307577343176, PRECISION@10 = 0.03832820448408216 [2e+00s]\n",
            "epoch=10, loss = 49779.703125[4e+00s] HitRatio@10 = 0.297682597500471, RECAll@10 = 0.050803222906152565, PRECISION@10 = 0.03955284808139444 [2e+00s]\n",
            "epoch=11, loss = 44701.21875[4e+00s] HitRatio@10 = 0.2997550712805376, RECAll@10 = 0.051510588271444724, PRECISION@10 = 0.03996734283740775 [2e+00s]\n",
            "epoch=12, loss = 40370.9921875[4e+00s] HitRatio@10 = 0.31168749607486024, RECAll@10 = 0.054127341429959605, PRECISION@10 = 0.04183884946304393 [2e+00s]\n",
            "epoch=13, loss = 36411.046875[4e+00s] HitRatio@10 = 0.3148904100985995, RECAll@10 = 0.05513392641622126, PRECISION@10 = 0.04239150913772834 [2e+00s]\n",
            "epoch=14, loss = 33188.3046875[6e+00s] HitRatio@10 = 0.32186145826791435, RECAll@10 = 0.05671358573839866, PRECISION@10 = 0.043264460214786825 [2e+00s]\n",
            "epoch=15, loss = 30085.51953125[4e+00s] HitRatio@10 = 0.3255039879419707, RECAll@10 = 0.05816176347580938, PRECISION@10 = 0.043999246373174296 [2e+00s]\n",
            "epoch=16, loss = 27712.986328125[4e+00s] HitRatio@10 = 0.33435910318407336, RECAll@10 = 0.060126198383618636, PRECISION@10 = 0.04526157131194226 [2e+00s]\n",
            "epoch=17, loss = 25065.083984375[4e+00s] HitRatio@10 = 0.33354267411919863, RECAll@10 = 0.06010414386299961, PRECISION@10 = 0.045167367958302895 [2e+00s]\n",
            "epoch=18, loss = 22990.15625[4e+00s] HitRatio@10 = 0.3365571814356591, RECAll@10 = 0.06106567827458174, PRECISION@10 = 0.04591471456384207 [2e+00s]\n",
            "epoch=19, loss = 21172.765625[6e+00s] HitRatio@10 = 0.34151855806066694, RECAll@10 = 0.06224725314371818, PRECISION@10 = 0.046335489543431564 [2e+00s]\n",
            "epoch=20, loss = 19569.033203125[4e+00s] HitRatio@10 = 0.34428185643408904, RECAll@10 = 0.06320220814802785, PRECISION@10 = 0.046906989888843856 [2e+00s]\n",
            "epoch=21, loss = 17927.470703125[4e+00s] HitRatio@10 = 0.3491176285875777, RECAll@10 = 0.06417980890311331, PRECISION@10 = 0.04755385291716778 [2e+00s]\n",
            "epoch=22, loss = 16762.904296875[4e+00s] HitRatio@10 = 0.3517553224894806, RECAll@10 = 0.06479404009741645, PRECISION@10 = 0.04781762230735821 [2e+00s]\n",
            "epoch=23, loss = 15587.4775390625[4e+00s] HitRatio@10 = 0.3530741694404321, RECAll@10 = 0.06539363464129712, PRECISION@10 = 0.047974627896757126 [2e+00s]\n",
            "epoch=24, loss = 14524.6806640625[6e+00s] HitRatio@10 = 0.35445581862714315, RECAll@10 = 0.06578769102259381, PRECISION@10 = 0.048175595051187785 [2e+00s]\n",
            "epoch=25, loss = 13406.83984375[4e+00s] HitRatio@10 = 0.35445581862714315, RECAll@10 = 0.06627747403159842, PRECISION@10 = 0.04834516108773862 [2e+00s]\n",
            "epoch=26, loss = 12721.8837890625[4e+00s] HitRatio@10 = 0.357407523707844, RECAll@10 = 0.06643325438918986, PRECISION@10 = 0.048382842429194474 [2e+00s]\n",
            "epoch=27, loss = 11901.634765625[4e+00s] HitRatio@10 = 0.35684230358600766, RECAll@10 = 0.0665981820689888, PRECISION@10 = 0.04845192488853004 [2e+00s]\n",
            "epoch=28, loss = 11143.7890625[4e+00s] HitRatio@10 = 0.3547070275701815, RECAll@10 = 0.0660703560718561, PRECISION@10 = 0.047666896941535176 [2e+00s]\n",
            "epoch=29, loss = 10480.6328125[4e+00s] HitRatio@10 = 0.3528229604973937, RECAll@10 = 0.06612874821988637, PRECISION@10 = 0.04775482007159847 [2e+00s]\n",
            "epoch=30, loss = 9993.5615234375[6e+00s] HitRatio@10 = 0.35502103874897945, RECAll@10 = 0.06689670306146031, PRECISION@10 = 0.04793066633172546 [2e+00s]\n",
            "epoch=31, loss = 9463.9677734375[4e+00s] HitRatio@10 = 0.35677950135024805, RECAll@10 = 0.06732856043029717, PRECISION@10 = 0.048194435721915785 [2e+00s]\n",
            "epoch=32, loss = 8990.1357421875[4e+00s] HitRatio@10 = 0.3555234566350562, RECAll@10 = 0.06703608502471628, PRECISION@10 = 0.04794322677887735 [2e+00s]\n",
            "epoch=33, loss = 8498.458984375[4e+00s] HitRatio@10 = 0.3562770834641713, RECAll@10 = 0.06686833684132137, PRECISION@10 = 0.04784902342523793 [2e+00s]\n",
            "epoch=34, loss = 8072.50927734375[4e+00s] HitRatio@10 = 0.35502103874897945, RECAll@10 = 0.0668798073262708, PRECISION@10 = 0.04774225962444667 [2e+00s]\n",
            "epoch=35, loss = 7741.10693359375[6e+00s] HitRatio@10 = 0.35520944545625827, RECAll@10 = 0.06700633081364814, PRECISION@10 = 0.047698298059415035 [2e+00s]\n",
            "epoch=36, loss = 7276.41455078125[4e+00s] HitRatio@10 = 0.35539785216353703, RECAll@10 = 0.06698114645485347, PRECISION@10 = 0.047648056270807274 [2e+00s]\n",
            "epoch=37, loss = 7099.70361328125[4e+00s] HitRatio@10 = 0.3525089493185957, RECAll@10 = 0.06674272342369002, PRECISION@10 = 0.047365446209889035 [2e+00s]\n",
            "epoch=38, loss = 6738.0302734375[4e+00s] HitRatio@10 = 0.35131570683916347, RECAll@10 = 0.06602340039592038, PRECISION@10 = 0.046932110783147844 [2e+00s]\n",
            "epoch=39, loss = 6541.54296875[4e+00s] HitRatio@10 = 0.35131570683916347, RECAll@10 = 0.06643653683279191, PRECISION@10 = 0.04691327011241998 [2e+00s]\n",
            "epoch=40, loss = 6222.31787109375[6e+00s] HitRatio@10 = 0.35150411354644223, RECAll@10 = 0.06671193680735471, PRECISION@10 = 0.046699742510837354 [2e+00s]\n",
            "epoch=41, loss = 5992.11962890625[4e+00s] HitRatio@10 = 0.34880361740877974, RECAll@10 = 0.06622576493441518, PRECISION@10 = 0.04636061043773545 [2e+00s]\n",
            "epoch=42, loss = 5797.23876953125[4e+00s] HitRatio@10 = 0.3431514161904164, RECAll@10 = 0.06570226546229874, PRECISION@10 = 0.045789110092322956 [2e+00s]\n",
            "epoch=43, loss = 5654.5361328125[4e+00s] HitRatio@10 = 0.34359103184073353, RECAll@10 = 0.06496367174004665, PRECISION@10 = 0.045343214218429864 [2e+00s]\n",
            "epoch=44, loss = 5349.525390625[4e+00s] HitRatio@10 = 0.3417697670037053, RECAll@10 = 0.06499870528582527, PRECISION@10 = 0.04520504929975871 [2e+00s]\n",
            "epoch=45, loss = 5312.6591796875[6e+00s] HitRatio@10 = 0.3407649312315518, RECAll@10 = 0.06468882763925297, PRECISION@10 = 0.04475287320228959 [2e+00s]\n",
            "epoch=46, loss = 5097.93408203125[4e+00s] HitRatio@10 = 0.33819003956540855, RECAll@10 = 0.06418261906268304, PRECISION@10 = 0.044394900458459924 [2e+00s]\n",
            "epoch=47, loss = 4935.49951171875[4e+00s] HitRatio@10 = 0.3362431702568611, RECAll@10 = 0.06400814149503246, PRECISION@10 = 0.04409972995038981 [2e+00s]\n",
            "epoch=48, loss = 4873.85986328125[4e+00s] HitRatio@10 = 0.33222382716824717, RECAll@10 = 0.06359775670080528, PRECISION@10 = 0.043798279218743644 [2e+00s]\n",
            "epoch=49, loss = 4733.080078125[4e+00s] HitRatio@10 = 0.334107894241035, RECAll@10 = 0.06374993365848122, PRECISION@10 = 0.04377315832443988 [2e+00s]\n",
            "epoch=50, loss = 4548.0810546875[6e+00s] HitRatio@10 = 0.3312189913960937, RECAll@10 = 0.06333670375067234, PRECISION@10 = 0.04328330088551497 [2e+00s]\n",
            "epoch=51, loss = 4460.60693359375[4e+00s] HitRatio@10 = 0.3327262450543239, RECAll@10 = 0.06335736974710385, PRECISION@10 = 0.043000690824596816 [2e+00s]\n",
            "epoch=52, loss = 4384.51123046875[4e+00s] HitRatio@10 = 0.3282672863153928, RECAll@10 = 0.06267055045499471, PRECISION@10 = 0.042598756515735255 [2e+00s]\n",
            "epoch=53, loss = 4335.26123046875[4e+00s] HitRatio@10 = 0.32431074546253846, RECAll@10 = 0.06222161262862168, PRECISION@10 = 0.04214658041826609 [2e+00s]\n",
            "epoch=54, loss = 4220.5859375[4e+00s] HitRatio@10 = 0.3238083275764617, RECAll@10 = 0.06208932355078811, PRECISION@10 = 0.04195817371098733 [2e+00s]\n",
            "epoch=55, loss = 4113.90087890625[4e+00s] HitRatio@10 = 0.3202914023739245, RECAll@10 = 0.061677695702231014, PRECISION@10 = 0.041480876719214355 [2e+00s]\n",
            "epoch=56, loss = 4038.6162109375[6e+00s] HitRatio@10 = 0.32004019343088613, RECAll@10 = 0.061395176662207555, PRECISION@10 = 0.04116058531684045 [2e+00s]\n",
            "epoch=57, loss = 3991.830810546875[4e+00s] HitRatio@10 = 0.3165232682283489, RECAll@10 = 0.061170927177169696, PRECISION@10 = 0.04085913458519431 [2e+00s]\n",
            "epoch=58, loss = 3955.330810546875[4e+00s] HitRatio@10 = 0.3174653017647428, RECAll@10 = 0.06142040057285085, PRECISION@10 = 0.040815173020162625 [2e+00s]\n",
            "epoch=59, loss = 3852.12109375[4e+00s] HitRatio@10 = 0.31916096213025186, RECAll@10 = 0.061376999449647085, PRECISION@10 = 0.040702128995795395 [2e+00s]\n",
            "epoch=60, loss = 3766.9716796875[4e+00s] HitRatio@10 = 0.3176537084720216, RECAll@10 = 0.060742582515618086, PRECISION@10 = 0.04040695848772527 [2e+00s]\n",
            "epoch=61, loss = 3686.627197265625[6e+00s] HitRatio@10 = 0.31426238774100357, RECAll@10 = 0.06022426148852139, PRECISION@10 = 0.039904540601648435 [2e+00s]\n",
            "epoch=62, loss = 3659.429931640625[4e+00s] HitRatio@10 = 0.31363436538340767, RECAll@10 = 0.060214965274842054, PRECISION@10 = 0.03976009545940141 [2e+00s]\n",
            "epoch=63, loss = 3586.3212890625[4e+00s] HitRatio@10 = 0.3102430446523896, RECAll@10 = 0.059490660142910816, PRECISION@10 = 0.03943980405702737 [2e+00s]\n",
            "epoch=64, loss = 3542.761962890625[4e+00s] HitRatio@10 = 0.3079193619292847, RECAll@10 = 0.05902228322414733, PRECISION@10 = 0.03914463354895722 [2e+00s]\n",
            "epoch=65, loss = 3521.1669921875[4e+00s] HitRatio@10 = 0.3057840859134585, RECAll@10 = 0.05853296779306284, PRECISION@10 = 0.03865477611003233 [2e+00s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3da62d93347f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#bpr = TextBPR(yelp, latent_factors, text_factors, learning_rate, reg, init_mean, init_stdev, alpha)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mbpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# 학습된 가중치 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cd662c78e3b5>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self, epoch, batch_size, topK)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# 성능 측정 함수를 통해 HitRatio 및 NDCG를 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mhits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch={epoc}, loss = {iter_loss}[{t2-t1:.1}s] HitRatio@{topK} = {hits}, RECAll@{topK} = {recall}, PRECISION@{topK} = {precision} [{time.time()-t2:.1}s]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cd662c78e3b5>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(self, test, K)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0msum_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mset_topk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtop_indicies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mset_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cd662c78e3b5>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0msum_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mset_topk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtop_indicies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mset_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    np.random.seed(30)  # 시드 설정을 통해 일관된 결과를 얻기 위해\n",
        "\n",
        "    #yelp = Yelp()\n",
        "\n",
        "    latent_factors = 768  # 잠재요인 수\n",
        "    text_factors = 768  # 텍스트 잠재요인 수\n",
        "    learning_rate = 0.0005  # 학습률\n",
        "    reg = 1e-4  # 정규화 계수\n",
        "    init_mean = 0  # 초기 가중치 평균\n",
        "    init_stdev = 0.001  # 초기 가중치 표준편차\n",
        "    epoch = 100  # 최대 반복 횟수\n",
        "    batch_size = 1024  # 미니배치 크기\n",
        "    alpha = 0.75\n",
        "    num_thread = mp.cpu_count() # 사용할 스레드 수\n",
        "    print(\"thread num: \", num_thread)\n",
        "    K = 10\n",
        "    print(\"#factors: %d, lr: %f, reg: %f, batch_size: %d\" % (latent_factors, learning_rate, reg, batch_size))\n",
        "\n",
        "    # MF-BPR 모델 생성 및 학습\n",
        "    #bpr = MFbpr(yelp, latent_factors, learning_rate, reg, init_mean, init_stdev)\n",
        "    bpr = TextBPR(yelp, latent_factors, text_factors, learning_rate, reg, init_mean, init_stdev, alpha)\n",
        "\n",
        "    bpr.build_model(epoch, batch_size=batch_size, topK = K)\n",
        "\n",
        "    # 학습된 가중치 저장\n",
        "    # np.save(\"out/u\"+str(learning_rate)+\".npy\", bpr.U.detach().numpy())\n",
        "    # np.save(\"out/v\"+str(learning_rate)+\".npy\", bpr.V.detach().numpy())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
