{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c099ff43-1242-4b93-b751-178e9956c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import math\n",
    "import heapq \n",
    "\n",
    "import multiprocessing as mp\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2063392d-ed4d-4cd8-bb06-3bd58e832b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFbpr(nn.Module):\n",
    "    '''\n",
    "    BPR learning for MF model\n",
    "    '''\n",
    "    def __init__(self, dataset, factors, learning_rate, reg, init_mean, init_stdev):\n",
    "        super(MFbpr, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.train = dataset.train\n",
    "        self.test = dataset.test\n",
    "        self.num_user = dataset.num_user\n",
    "        self.num_item = dataset.num_item\n",
    "        self.neg = dataset.neg\n",
    "        self.factors = factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg = reg\n",
    "        self.init_mean = init_mean\n",
    "        self.init_stdev = init_stdev\n",
    "\n",
    "        # user & item latent vectors\n",
    "        self.U = nn.Parameter(torch.normal(mean=self.init_mean * torch.ones(self.num_user, self.factors), std=self.init_stdev))\n",
    "        self.V = nn.Parameter(torch.normal(mean=self.init_mean * torch.ones(self.num_item, self.factors), std=self.init_stdev))\n",
    "        self.U = self.U.cuda()\n",
    "        self.V = self.V.cuda()\n",
    "        # optim\n",
    "        self.mf_optim = optim.Adam([self.U, self.V], lr=self.learning_rate)\n",
    "\n",
    "        self.items_of_user = []\n",
    "        self.num_rating = 0     # number of ratings\n",
    "        for u in range(len(self.train)):\n",
    "            self.items_of_user.append(set([]))\n",
    "            for i in range(len(self.train[u])):\n",
    "                item = self.train[u][i][0]\n",
    "                self.items_of_user[u].add(item)\n",
    "                self.num_rating += 1\n",
    "\n",
    "    def forward(self, u, i, j):\n",
    "        y_ui = torch.diag(torch.mm(self.U[u], self.V[i].t()))\n",
    "        y_uj = torch.diag(torch.mm(self.U[u], self.V[j].t()))\n",
    "        regularizer = self.reg * (torch.sum(self.U[u] ** 2) + torch.sum(self.V[i] ** 2) + torch.sum(self.V[j] ** 2))\n",
    "        loss = regularizer - torch.sum(torch.log2(torch.sigmoid(y_ui - y_uj)))\n",
    "        return y_ui, y_uj, loss\n",
    "\n",
    "    def build_model(self, epoch=30, num_thread=4, batch_size=32):\n",
    "        data_loader = DataLoader(self.dataset, batch_size=batch_size, pin_memory=True)  # 데이터 로딩 시 CUDA 사용\n",
    "        print(\"Training MF-BPR with: learning_rate=%.4f, regularization=%.4f, factors=%d, #epoch=%d, batch_size=%d.\"\n",
    "              % (self.learning_rate, self.reg, self.factors, epoch, batch_size))\n",
    "        t1 = time.time()\n",
    "        iter_loss = 0\n",
    "        for epoc in range(epoch):\n",
    "            for s, (users, items_pos, items_neg) in enumerate(data_loader):\n",
    "                self.mf_optim.zero_grad()\n",
    "                y_ui, y_uj, loss = self.forward(users.cuda(non_blocking=True), items_pos.cuda(non_blocking=True), items_neg.cuda(non_blocking=True))  # 입력 데이터 CUDA 사용\n",
    "                iter_loss += loss\n",
    "                loss.backward()\n",
    "                self.mf_optim.step()\n",
    "\n",
    "            if epoc % 20 == 19:\n",
    "                t2 = time.time()\n",
    "                topK = 20\n",
    "                (hits, ndcgs) = evaluate_model(self, self.test, topK, num_thread)\n",
    "                hr_mean = np.array(hits).mean()\n",
    "                ndcg_mean = np.array(ndcgs).mean()\n",
    "                \n",
    "                print(\"Epoch=%d [%.1f s] HitRatio@%d = %.4f, NDCG@%d = %.4f [%.1f s]\"\n",
    "                      % (epoc, (t2 - t1) / 20, topK, hr_mean, topK, ndcg_mean, time.time() - t2))\n",
    "                t1 = time.time()\n",
    "                iter_loss = 0\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        return torch.matmul(self.U[u].detach().cpu(), self.V[i].detach().cpu())\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        users, pos_items, neg_items = [], [], []\n",
    "        for i in range(batch_size):\n",
    "            u = np.random.randint(0, self.num_user)\n",
    "            i = self.train[u][np.random.randint(0, len(self.train[u]))][0]\n",
    "            j = np.random.randint(0, self.num_item)\n",
    "            while j in self.items_of_user[u]:\n",
    "                j = np.random.randint(0, self.num_item)\n",
    "            users.append(u)\n",
    "            pos_items.append(i)\n",
    "            neg_items.append(j)\n",
    "        return (users, pos_items, neg_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8895e323-9f71-4134-924b-3ee24cb6160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadRatingFile_HoldKOut(filename, splitter, K):\n",
    "    train = []  \n",
    "    test = []\n",
    "    \n",
    "    num_ratings = 0\n",
    "    num_item = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        line = f.readline()\n",
    "        while line != None and line != \"\":\n",
    "            arr = line.split(splitter)\n",
    "            if (len(arr) < 4):\n",
    "                continue\n",
    "            user, item, time = int(arr[0]), int(arr[1]), int(arr[3]) \n",
    "            if (len(train) <= user):\n",
    "                train.append([])\n",
    "            train[user].append([item, time])\n",
    "            num_ratings += 1\n",
    "            num_item = max(item, num_item)\n",
    "            line = f.readline()\n",
    "    num_user = len(train)\n",
    "    num_item = num_item + 1\n",
    "    \n",
    "    def getTime(item):\n",
    "        return item[-1];\n",
    "    for u in range (len(train)):\n",
    "        train[u] = sorted(train[u], key = getTime)\n",
    "    \n",
    "    for u in range (len(train)):\n",
    "        for k in range(K):\n",
    "            if (len(train[u]) == 0):\n",
    "                break\n",
    "            test.append([u, train[u][-1][0], train[u][-1][1]])\n",
    "            del train[u][-1]\n",
    "            \n",
    "    test = sorted(test, key = getTime)\n",
    "    \n",
    "    return train, test, num_user, num_item, num_ratings\n",
    "\n",
    "\n",
    "class Pinterest(Dataset):\n",
    "    def __init__(self, dir, splitter, K):\n",
    "        self.train = []\n",
    "        \n",
    "        self.num_ratings = 0\n",
    "        self.num_item = 0\n",
    "        with open(dir+'pos.txt', \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(splitter)\n",
    "                if (len(arr) < 2):\n",
    "                    continue\n",
    "                user, item = int(arr[0]), int(arr[1])\n",
    "                if (len(self.train) <= user):\n",
    "                    self.train.append([])\n",
    "                self.train[user].append([item])\n",
    "                self.num_ratings += 1\n",
    "                self.num_item = max(item, self.num_item)\n",
    "                line = f.readline()\n",
    "        self.num_user = len(self.train)\n",
    "        self.num_item = self.num_item + 1\n",
    "\n",
    "        self.test = []\n",
    "        self.neg = dict()\n",
    "        user = 0\n",
    "        with open(dir+'neg.txt', 'r') as f_neg:\n",
    "            line = f_neg.readline()\n",
    "            while line != None and line != '':\n",
    "                arr = line.split(splitter)\n",
    "                pos = int(arr[0])\n",
    "                self.test.append([user, pos])\n",
    "                self.neg[user] = []\n",
    "                for neg_i in range(len(arr)):\n",
    "                    if arr[neg_i] != '\\n':\n",
    "                        self.neg[user].append(int(arr[neg_i]))\n",
    "\n",
    "                user += 1\n",
    "                line = f_neg.readline()\n",
    "        print(\"#users: %d, #items: %d, #ratings: %d\" %(self.num_user, self.num_item, self.num_ratings))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_user\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u = idx\n",
    "        i = self.train[u][np.random.randint(0, len(self.train[u]))]\n",
    "        j = np.random.randint(0, self.num_item)\n",
    "        while j in self.train[u]:\n",
    "            j = np.random.randint(0, self.num_item) \n",
    "        \n",
    "        return (u, i, j)\n",
    "\n",
    "# 데이터셋을 GPU로 전송하는 부분\n",
    "pinterest_dataset = Pinterest(dir='path_to_your_data_directory', splitter=' ', K=your_K_value)\n",
    "pinterest_dataset = pinterest_dataset.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6300f0d4-10c9-4b4f-8260-93512e101fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables that are shared across processes\n",
    "_model = None\n",
    "_testRatings = None\n",
    "_K = None\n",
    "\n",
    "def evaluate_model(model, testRatings, K, num_thread):\n",
    "    \"\"\"\n",
    "    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation\n",
    "    Return: score of each test rating.\n",
    "    \"\"\"\n",
    "    global _model\n",
    "    global _testRatings\n",
    "    global _K\n",
    "    _model = model\n",
    "    _testRatings = testRatings\n",
    "    _K = K\n",
    "    num_rating = len(testRatings)\n",
    "\n",
    "    pool = mp.Pool(processes=num_thread)\n",
    "    res = pool.map(eval_one_rating, range(num_rating))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    hits = [r[0] for r in res]\n",
    "    ndcgs = [r[1] for r in res]\n",
    "    return (hits, ndcgs)\n",
    "\n",
    "def eval_one_rating(idx):\n",
    "    rating = _testRatings[idx]\n",
    "    hr = ndcg = 0\n",
    "    u = rating[0]\n",
    "    gtItem = rating[1]\n",
    "    map_item_score = {}\n",
    "    \n",
    "    # Get the score of the test item first\n",
    "    maxScore = _model.predict(u, gtItem)\n",
    "    \n",
    "    # Early stopping if there are K items larger than maxScore.\n",
    "    countLarger = 0\n",
    "    for i in _model.neg[u]:\n",
    "        early_stop = False\n",
    "        score = _model.predict(u, i)\n",
    "        map_item_score[i] = score\n",
    "\n",
    "        if score > maxScore:\n",
    "            countLarger += 1\n",
    "        if countLarger > _K:\n",
    "            hr = ndcg = 0\n",
    "            early_stop = True\n",
    "            break\n",
    "    # Generate topK rank list\n",
    "    if not early_stop:\n",
    "        items = torch.tensor(list(map_item_score.keys())).cuda()\n",
    "        scores = torch.tensor(list(map_item_score.values())).cuda()\n",
    "        _, indices = torch.topk(scores, _K)\n",
    "        ranklist = items[indices.cpu()]\n",
    "        hr = getHitRatio(ranklist, gtItem)\n",
    "        ndcg = getNDCG(ranklist, gtItem)\n",
    "\n",
    "    return (hr, ndcg)\n",
    "\n",
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c55f8-8d75-4f61-80ae-d9c6666237e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#users: 14470, #items: 9396, #ratings: 50000\n",
      "#factors: 64, lr: 0.000300, reg: 0.010000, batch_size: 32\n",
      "Training MF-BPR with: learning_rate=0.0003, regularization=0.0100, factors=64, #epoch=10000, batch_size=32.\n"
     ]
    }
   ],
   "source": [
    "def parse_args():\n",
    "    args = argparse.Namespace()\n",
    "    args.batch_size = 32\n",
    "    args.learning_rate = 0.0003\n",
    "    return args\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load data\n",
    "    dataset = \"./data/\"\n",
    "    splitter = \" \"\n",
    "    hold_k_out = 1\n",
    "    pinterest = Pinterest(dataset, splitter, hold_k_out)\n",
    "    \n",
    "    # MFbpr parameters\n",
    "    factors = 64\n",
    "    learning_rate = args.learning_rate\n",
    "    reg = 0.01\n",
    "    init_mean = 0\n",
    "    init_stdev = 0.01\n",
    "    epoch = 30\n",
    "    batch_size = args.batch_size\n",
    "    num_thread = mp.cpu_count()\n",
    "    print(\"#factors: %d, lr: %f, reg: %f, batch_size: %d\" % (factors, learning_rate, reg, batch_size))\n",
    "    \n",
    "    # Run model\n",
    "    bpr = MFbpr(pinterest,\n",
    "                factors, learning_rate, reg, init_mean, init_stdev).to(device)\n",
    "    bpr.build_model(epoch, num_thread, batch_size=batch_size)\n",
    "\n",
    "    # save model\n",
    "    np.save(\"out/u\"+str(learning_rate)+\".npy\", bpr.U.detach().cpu().numpy())\n",
    "    np.save(\"out/v\"+str(learning_rate)+\".npy\", bpr.V.detach().cpu().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
