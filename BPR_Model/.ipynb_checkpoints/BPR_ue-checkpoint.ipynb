{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import random\n",
        "\n",
        "# # CSV 파일을 읽어옴\n",
        "# df = pd.read_csv('test_set.csv')\n",
        "\n",
        "# # item의 최대값 계산\n",
        "# max_item = df['item'].max()\n",
        "\n",
        "# # user 별로 방문하지 않은 장소들을 저장할 딕셔너리 생성\n",
        "# user_not_visited = {}\n",
        "\n",
        "# # 각 user에 대해 방문하지 않은 장소들을 구함\n",
        "# for user_id, group in df.groupby('user'):\n",
        "#     visited_items = set(group['item'])\n",
        "#     not_visited_items = [str(item) for item in range(0, max_item) if item not in visited_items]\n",
        "#     # 랜덤하게 100개의 장소 선택\n",
        "#     random_not_visited_items = random.sample(not_visited_items, min(100, len(not_visited_items)))\n",
        "#     user_not_visited[user_id] = random_not_visited_items\n",
        "\n",
        "# # 'neg.txt' 파일 생성\n",
        "# with open('neg.txt', 'w') as file:\n",
        "#     for user_id, not_visited_items in user_not_visited.items():\n",
        "#         for item in not_visited_items:\n",
        "#             file.write(f\"{item} \")\n",
        "#         file.write('\\n')\n"
      ],
      "metadata": {
        "id": "g-u6Px3_zh4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # CSV 파일을 읽어옴\n",
        "# df = pd.read_csv('test_set.csv')\n",
        "\n",
        "# # 'user'와 'item' 열 선택\n",
        "# user_item_df = df[['user', 'item']]\n",
        "\n",
        "# # 'pos.txt' 파일로 저장\n",
        "# user_item_df.to_csv('pos.txt', sep=' ', index=False, header=False)\n"
      ],
      "metadata": {
        "id": "ktgw5y271pz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import multiprocessing as mp\n",
        "import argparse\n",
        "\n",
        "import math\n",
        "import heapq # for retrieval topK\n",
        "import multiprocessing\n",
        "\n",
        "from numpy import random\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "_2wcNs_jzOcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVi2rdu0yu-1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "class MFbpr(nn.Module):\n",
        "    '''\n",
        "    MF 모델에 대한 BPR 학습\n",
        "    '''\n",
        "    def __init__(self, dataset, factors, learning_rate, reg, init_mean, init_stdev):\n",
        "        '''\n",
        "        생성자\n",
        "        Args:\n",
        "            dataset: 데이터셋 객체로, 학습 및 테스트 데이터를 포함합니다.\n",
        "            factors (int): 잠재 요인의 수.\n",
        "            learning_rate (float): 최적화에 사용되는 학습률.\n",
        "            reg (float): 정규화 강도.\n",
        "            init_mean (float): 초기화에 사용되는 정규 분포의 평균.\n",
        "            init_stdev (float): 초기화에 사용되는 정규 분포의 표준 편차.\n",
        "        '''\n",
        "        super(MFbpr, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.train = dataset.train\n",
        "        self.test = dataset.test\n",
        "        self.num_user = dataset.num_user\n",
        "        self.num_item = dataset.num_item\n",
        "        self.neg = dataset.neg\n",
        "        self.factors = factors\n",
        "        self.learning_rate = learning_rate\n",
        "        self.reg = reg\n",
        "        self.init_mean = init_mean\n",
        "        self.init_stdev = init_stdev\n",
        "\n",
        "        # 사용자와 아이템의 잠재 요인을 초기화합니다.\n",
        "        self.U = torch.normal(mean=self.init_mean * torch.ones(self.num_user, self.factors), std=self.init_stdev).requires_grad_()\n",
        "        self.V = torch.normal(mean=self.init_mean * torch.ones(self.num_item, self.factors), std=self.init_stdev).requires_grad_()\n",
        "\n",
        "        # Adam optimizer를 초기화합니다.\n",
        "        self.mf_optim = optim.Adam([self.U, self.V], lr=self.learning_rate)\n",
        "        self.items_of_user = []\n",
        "        self.num_rating = 0\n",
        "        for u in range(len(self.train)):\n",
        "            # 각 사용자가 평가한 아이템 목록을 저장합니다.\n",
        "            self.items_of_user.append(set([]))\n",
        "            for i in range(len(self.train[u])):\n",
        "                item = self.train[u][i][0]\n",
        "                self.items_of_user[u].add(item)\n",
        "                self.num_rating += 1\n",
        "\n",
        "\n",
        "    def forward(self, u, i, j):\n",
        "        '''\n",
        "        MF-BPR 모델의 forward pass입니다.\n",
        "        Args:\n",
        "            u: 사용자 ID.\n",
        "            i: 긍정적인 아이템 ID.\n",
        "            j: 부정적인 아이템 ID.\n",
        "        Returns:\n",
        "            y_ui: 사용자와 긍정적인 아이템 간의 예측 점수.\n",
        "            y_uj: 사용자와 부정적인 아이템 간의 예측 점수.\n",
        "            loss: BPR 손실.\n",
        "        '''\n",
        "        # 사용자와 긍정적인 아이템 간의 예측 점수 계산\n",
        "        y_ui = torch.diag(torch.mm(self.U[u], self.V[i].t()))\n",
        "        # 사용자와 부정적인 아이템 간의 예측 점수 계산\n",
        "        y_uj = torch.diag(torch.mm(self.U[u], self.V[j].t()))\n",
        "        # 정규화 항 계산\n",
        "        regularizer = self.reg * (torch.sum(self.U[u] ** 2) + torch.sum(self.V[i] ** 2) + torch.sum(self.V[j] ** 2))\n",
        "        # BPR 손실 계산\n",
        "        loss = regularizer - torch.sum(torch.log2(torch.sigmoid(y_ui - y_uj)))\n",
        "        return y_ui, y_uj, loss\n",
        "\n",
        "    def build_model(self, maxIter=100, num_thread=4, batch_size=32):\n",
        "        '''\n",
        "        MF-BPR 모델을 구축하고 학습합니다.\n",
        "        Args:\n",
        "            maxIter (int): 학습의 최대 반복 횟수.\n",
        "            num_thread (int): 병렬 실행을 위한 스레드 수.\n",
        "            batch_size (int): 학습용 배치 크기.\n",
        "        '''\n",
        "        data_loader = DataLoader(self.dataset, batch_size=batch_size)\n",
        "\n",
        "        print(\"학습 중: learning_rate=%.4f, 정규화=%.4f, 요인=%d, #epoch=%d, 배치 크기=%d.\"\n",
        "              % (self.learning_rate, self.reg, self.factors, maxIter, batch_size))\n",
        "        t1 = time.time()\n",
        "        iter_loss = 0\n",
        "        for iteration in range(maxIter):\n",
        "            for s, (users, items_pos, items_neg) in enumerate(data_loader):\n",
        "                # 기울기 초기화\n",
        "                self.mf_optim.zero_grad()\n",
        "                # Forward pass를 통해 예측과 손실 계산\n",
        "                y_ui, y_uj, loss = self.forward(users, items_pos, items_neg)\n",
        "                iter_loss += loss\n",
        "                # Backward pass 및 파라미터 업데이트\n",
        "                loss.backward()\n",
        "                self.mf_optim.step()\n",
        "\n",
        "            if iteration % 20 == 19:\n",
        "                t2 = time.time()\n",
        "                topK = 20\n",
        "                # 성능 측정 함수를 통해 HitRatio 및 NDCG를 계산\n",
        "                (hits, ndcgs) = evaluate_model(self, self.test, topK, num_thread)\n",
        "                hr_mean = np.array(hits).mean()\n",
        "                ndcg_mean = np.array(ndcgs).mean()\n",
        "\n",
        "                print(\"반복=%d [%.1f s] HitRatio@%d = %.4f, NDCG@%d = %.4f [%.1f s]\"\n",
        "                      % (iteration, (t2 - t1) / 20, topK, hr_mean, topK, ndcg_mean, time.time() - t2))\n",
        "                t1 = time.time()\n",
        "                iter_loss = 0\n",
        "\n",
        "\n",
        "    def predict(self, u, i):\n",
        "        '''\n",
        "        사용자와 아이템 사이의 점수를 예측합니다.\n",
        "        Args:\n",
        "            u: 사용자 ID.\n",
        "            i: 아이템 ID.\n",
        "        Returns:\n",
        "            score: 사용자와 아이템 사이의 예측 점수.\n",
        "        '''\n",
        "        return np.inner(self.U[u].detach().numpy(), self.V[i].detach().numpy())\n",
        "\n",
        "    def get_batch(self, batch_size):\n",
        "        '''\n",
        "        학습 데이터의 배치를 가져옵니다.\n",
        "        Args:\n",
        "            batch_size (int): 배치 크기.\n",
        "        Returns:\n",
        "            users: 사용자 ID 목록.\n",
        "            pos_items: 긍정적인 아이템 ID 목록.\n",
        "            neg_items: 부정적인 아이템 ID 목록.\n",
        "        '''\n",
        "        users, pos_items, neg_items = [], [], []\n",
        "        for i in range(batch_size):\n",
        "            u = np.random.randint(0, self.num_user)\n",
        "            i = self.train[u][np.random.randint(0, len(self.train[u]))][0]\n",
        "            j = np.random.randint(0, self.num_item)\n",
        "            while j in self.items_of_user[u]:\n",
        "                j = np.random.randint(0, self.num_item)\n",
        "            users.append(u)\n",
        "            pos_items.append(i)\n",
        "            neg_items.append(j)\n",
        "        return (users, pos_items, neg_items)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mxt0aQC0DIkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LoadRatingFile_HoldKOut(filename, splitter, K):\n",
        "    \"\"\"\n",
        "    주어진 .rating 파일을 읽고 Hold-K-Out 교차 검증을 위한 학습 및 테스트 데이터를 생성합니다.\n",
        "\n",
        "    Args:\n",
        "        filename (str): .rating 파일의 경로.\n",
        "        splitter (str): 파일에서 열을 구분하는 구분자.\n",
        "        K (int): K 값, 즉 각 사용자마다 테스트에 사용되는 상호작용의 수.\n",
        "\n",
        "    Returns:\n",
        "        train (list): Hold-K-Out 교차 검증을 위한 학습 데이터.\n",
        "        test (list): Hold-K-Out 교차 검증을 위한 테스트 데이터.\n",
        "        num_user (int): 사용자 수.\n",
        "        num_item (int): 아이템 수.\n",
        "        num_ratings (int): 전체 상호작용 수.\n",
        "    \"\"\"\n",
        "    train = []\n",
        "    test = []\n",
        "\n",
        "    num_ratings = 0\n",
        "    num_item = 0\n",
        "    # 파일을 읽어서 train 및 test 데이터 생성\n",
        "    with open(filename, \"r\") as f:\n",
        "        line = f.readline()\n",
        "        while line != None and line != \"\":\n",
        "            arr = line.split(splitter)\n",
        "            if (len(arr) < 4):\n",
        "                continue\n",
        "            user, item, time = int(arr[0]), int(arr[1]), int(arr[3])\n",
        "            # 사용자별로 상호작용 데이터를 저장\n",
        "            if (len(train) <= user):\n",
        "                train.append([])\n",
        "            train[user].append([item, time])\n",
        "            num_ratings += 1\n",
        "            num_item = max(item, num_item)\n",
        "            line = f.readline()\n",
        "    num_user = len(train)\n",
        "    num_item = num_item + 1\n",
        "\n",
        "    # 상호작용 데이터를 시간순으로 정렬\n",
        "    def getTime(item):\n",
        "        return item[-1];\n",
        "    for u in range (len(train)):\n",
        "        train[u] = sorted(train[u], key = getTime)\n",
        "\n",
        "    # Hold-K-Out 교차 검증을 위해 학습 및 테스트 데이터 생성\n",
        "    for u in range (len(train)):\n",
        "        for k in range(K):\n",
        "            if (len(train[u]) == 0):\n",
        "                break\n",
        "            # 가장 최근에 발생한 상호작용을 테스트 데이터로 이동\n",
        "            test.append([u, train[u][-1][0], train[u][-1][1]])\n",
        "            del train[u][-1]\n",
        "\n",
        "    test = sorted(test, key = getTime)\n",
        "\n",
        "    return train, test, num_user, num_item, num_ratings\n",
        "\n",
        "class Pinterest(Dataset):\n",
        "    def __init__(self, dir, splitter, K):\n",
        "        \"\"\"\n",
        "        Pinterest 데이터셋을 로드하고 학습 데이터와 테스트 데이터를 생성합니다.\n",
        "\n",
        "        Args:\n",
        "            dir (str): 데이터 파일이 있는 디렉토리 경로.\n",
        "            splitter (str): 파일에서 열을 구분하는 구분자.\n",
        "            K (int): K 값, 즉 각 사용자마다 테스트에 사용되는 상호작용의 수.\n",
        "        \"\"\"\n",
        "\n",
        "        self.train = []\n",
        "\n",
        "        self.num_ratings = 0\n",
        "        self.num_item = 0\n",
        "        # pos.txt 파일을 읽어서 학습 데이터 생성\n",
        "        with open(dir+'pos.txt', \"r\") as f:\n",
        "            line = f.readline()\n",
        "            while line != None and line != \"\":\n",
        "                arr = line.split(splitter)\n",
        "                if (len(arr) < 2):\n",
        "                    continue\n",
        "                user, item = int(arr[0]), int(arr[1])\n",
        "                # 사용자별로 상호작용 데이터를 저장\n",
        "                if (len(self.train) <= user):\n",
        "                    self.train.append([])\n",
        "                self.train[user].append([item])\n",
        "                self.num_ratings += 1\n",
        "                self.num_item = max(item, self.num_item)\n",
        "                line = f.readline()\n",
        "        self.num_user = len(self.train)\n",
        "        self.num_item = self.num_item + 1\n",
        "\n",
        "        self.test = []\n",
        "        self.neg = dict()\n",
        "        user = 0\n",
        "        # neg.txt 파일을 읽어서 테스트 데이터 및 부정적 상호작용 데이터 생성\n",
        "        with open(dir+'neg.txt', 'r') as f_neg:\n",
        "            line = f_neg.readline()\n",
        "            while line != None and line != '':\n",
        "                arr = line.split(splitter)\n",
        "                pos = int(arr[0])\n",
        "                # 테스트 데이터 생성\n",
        "                self.test.append([user, pos])\n",
        "                # 사용자별로 부정적 상호작용 데이터 저장\n",
        "                self.neg[user] = []\n",
        "                for neg_i in range(len(arr)):\n",
        "                    if arr[neg_i] != '\\n':\n",
        "                        self.neg[user].append(int(arr[neg_i]))\n",
        "\n",
        "                user += 1\n",
        "                line = f_neg.readline()\n",
        "        print(\"#users: %d, #items: %d, #ratings: %d\" %(self.num_user, self.num_item, self.num_ratings))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        데이터셋의 사용자 수를 반환합니다.\n",
        "        \"\"\"\n",
        "        return self.num_user\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        데이터셋에서 하나의 샘플을 가져옵니다.\n",
        "\n",
        "        Args:\n",
        "            idx (int): 데이터셋 내의 인덱스.\n",
        "\n",
        "        Returns:\n",
        "            u: 사용자 ID.\n",
        "            i: 긍정적인 아이템 ID.\n",
        "            j: 부정적인 아이템 ID.\n",
        "        \"\"\"\n",
        "        u = idx\n",
        "        # 사용자별로 하나의 긍정적인 상호작용 선택\n",
        "        i = self.train[u][np.random.randint(0, len(self.train[u]))]\n",
        "        # 부정적인 상호작용 무작위 선택\n",
        "        j = np.random.randint(0, self.num_item)\n",
        "        while j in self.train[u]:\n",
        "            j = np.random.randint(0, self.num_item)\n",
        "        return (u, i, j)\n"
      ],
      "metadata": {
        "id": "3IGz-Xqc4kbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_model = None\n",
        "_testRatings = None\n",
        "_K = None\n",
        "\n",
        "def evaluate_model(model, testRatings, K, num_thread):\n",
        "    \"\"\"\n",
        "    Top-K 추천의 성능(Hit_Ratio, NDCG)을 평가합니다.\n",
        "    반환값: 각 테스트 상호작용의 점수.\n",
        "    \"\"\"\n",
        "    global _model\n",
        "    global _testRatings\n",
        "    global _K\n",
        "    _model = model\n",
        "    _testRatings = testRatings\n",
        "    _K = K\n",
        "    num_rating = len(testRatings)\n",
        "\n",
        "    # 멀티프로세싱을 사용하여 각 테스트 상호작용에 대한 평가 수행\n",
        "    pool = multiprocessing.Pool(processes=num_thread)\n",
        "    res = pool.map(eval_one_rating, range(num_rating))\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "\n",
        "    hits = [r[0] for r in res]\n",
        "    ndcgs = [r[1] for r in res]\n",
        "    return (hits, ndcgs)\n",
        "\n",
        "def eval_one_rating(idx):\n",
        "    rating = _testRatings[idx]\n",
        "    hr = ndcg = 0\n",
        "    u = rating[0]\n",
        "    gtItem = rating[1]\n",
        "    map_item_score = {}\n",
        "\n",
        "    maxScore = _model.predict(u, gtItem)\n",
        "\n",
        "    countLarger = 0\n",
        "\n",
        "    for i in _model.neg[u]:\n",
        "\n",
        "        early_stop = False\n",
        "        score = _model.predict(u, i)\n",
        "        map_item_score[i] = score\n",
        "\n",
        "        if score > maxScore:\n",
        "            countLarger += 1\n",
        "        if countLarger > _K:\n",
        "            hr = ndcg = 0\n",
        "            early_stop = True\n",
        "            break\n",
        "\n",
        "    if early_stop == False:\n",
        "        ranklist = heapq.nlargest(_K, map_item_score, key=map_item_score.get)\n",
        "        hr = getHitRatio(ranklist, gtItem)\n",
        "        ndcg = getNDCG(ranklist, gtItem)\n",
        "\n",
        "    return (hr, ndcg)\n",
        "\n",
        "def getHitRatio(ranklist, gtItem):\n",
        "    for item in ranklist:\n",
        "        if item == gtItem:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def getNDCG(ranklist, gtItem):\n",
        "    for i in range(len(ranklist)):\n",
        "        item = ranklist[i]\n",
        "        if item == gtItem:\n",
        "            return math.log(2) / math.log(i+2)\n",
        "    return 0"
      ],
      "metadata": {
        "id": "gxRHII-hy3f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_args():\n",
        "    \"\"\"\n",
        "    명령행 인자를 파싱합니다.\n",
        "    \"\"\"\n",
        "    args = argparse.Namespace()\n",
        "    args.batch_size = 32\n",
        "    args.learning_rate = 0.0003\n",
        "    return args\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = parse_args()\n",
        "    dataset = \"\"  # 데이터셋 디렉토리 또는 파일\n",
        "    splitter = \" \"  # 데이터 구분자\n",
        "    hold_k_out = 1  # Hold-K-Out 교차 검증의 K 값\n",
        "    pinterest = Pinterest(dataset, splitter, hold_k_out)\n",
        "\n",
        "    factors = 64  # 잠재요인 수\n",
        "    learning_rate = args.learning_rate  # 학습률\n",
        "    reg = 0.01  # 정규화 계수\n",
        "    init_mean = 0  # 초기 가중치 평균\n",
        "    init_stdev = 0.01  # 초기 가중치 표준편차\n",
        "    maxIter = 10000  # 최대 반복 횟수\n",
        "    batch_size = args.batch_size  # 미니배치 크기\n",
        "    num_thread = mp.cpu_count()  # 사용할 스레드 수\n",
        "    print(\"#factors: %d, lr: %f, reg: %f, batch_size: %d\" % (factors, learning_rate, reg, batch_size))\n",
        "\n",
        "    # MF-BPR 모델 생성 및 학습\n",
        "    bpr = MFbpr(pinterest, factors, learning_rate, reg, init_mean, init_stdev)\n",
        "    bpr.build_model(maxIter, num_thread, batch_size=batch_size)\n",
        "\n",
        "    # 학습된 가중치 저장\n",
        "    np.save(\"out/u\"+str(learning_rate)+\".npy\", bpr.U.detach().numpy())\n",
        "    np.save(\"out/v\"+str(learning_rate)+\".npy\", bpr.V.detach().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "HdkbsLOty5KZ",
        "outputId": "036b1d23-c763-4a32-b8b1-69844a791040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#users: 14470, #items: 9396, #ratings: 50000\n",
            "#factors: 64, lr: 0.000300, reg: 0.010000, batch_size: 32\n",
            "Training MF-BPR with: learning_rate=0.0003, regularization=0.0100, factors=64, #epoch=10000, batch_size=32.\n",
            "Iter=19 [6.9 s] HitRatio@20 = 0.1981, NDCG@20 = 0.0687 [16.2 s]\n",
            "Iter=39 [6.7 s] HitRatio@20 = 0.1992, NDCG@20 = 0.0697 [16.5 s]\n",
            "Iter=59 [6.9 s] HitRatio@20 = 0.1988, NDCG@20 = 0.0694 [16.1 s]\n",
            "Iter=79 [6.7 s] HitRatio@20 = 0.1965, NDCG@20 = 0.0693 [16.1 s]\n",
            "Iter=99 [6.8 s] HitRatio@20 = 0.1980, NDCG@20 = 0.0695 [16.5 s]\n",
            "Iter=119 [6.7 s] HitRatio@20 = 0.2006, NDCG@20 = 0.0700 [16.5 s]\n",
            "Iter=139 [7.3 s] HitRatio@20 = 0.1987, NDCG@20 = 0.0695 [16.1 s]\n",
            "Iter=159 [6.8 s] HitRatio@20 = 0.1999, NDCG@20 = 0.0705 [16.0 s]\n",
            "Iter=179 [6.9 s] HitRatio@20 = 0.1981, NDCG@20 = 0.0698 [16.8 s]\n",
            "Iter=199 [6.8 s] HitRatio@20 = 0.1996, NDCG@20 = 0.0701 [15.9 s]\n",
            "Iter=219 [6.8 s] HitRatio@20 = 0.1994, NDCG@20 = 0.0702 [16.0 s]\n",
            "Iter=239 [6.9 s] HitRatio@20 = 0.2006, NDCG@20 = 0.0702 [16.1 s]\n",
            "Iter=259 [6.9 s] HitRatio@20 = 0.2008, NDCG@20 = 0.0702 [16.0 s]\n",
            "Iter=279 [6.8 s] HitRatio@20 = 0.1992, NDCG@20 = 0.0701 [16.0 s]\n",
            "Iter=299 [6.8 s] HitRatio@20 = 0.2008, NDCG@20 = 0.0698 [16.1 s]\n",
            "Iter=319 [6.8 s] HitRatio@20 = 0.2019, NDCG@20 = 0.0701 [15.8 s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-0e198520b984>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     bpr = MFbpr(pinterest,\n\u001b[1;32m     29\u001b[0m                 factors, learning_rate, reg, init_mean, init_stdev)\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mbpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-fe9f4ad49d07>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self, maxIter, num_thread, batch_size)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m# back propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmf_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;31m# check performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m                             )\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 state_steps)\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    167\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    317\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}