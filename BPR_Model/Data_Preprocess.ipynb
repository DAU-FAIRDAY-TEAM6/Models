{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21166128-d366-4bb6-8b2a-c910d7ce9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "path = './test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c468b5",
   "metadata": {},
   "source": [
    "## Review 데이터 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4fb919",
   "metadata": {},
   "source": [
    "user_id 및 business_id 추출, 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ca32dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 데이터가 user_id와 business_id를 기준으로 정렬되어 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 파일 경로 설정\n",
    "json_file_path = path + 'review.json'\n",
    "\n",
    "# 유저 ID와 비즈니스 ID를 매핑하기 위한 딕셔너리\n",
    "user_id_mapping = {}\n",
    "business_id_mapping = {}\n",
    "next_user_index = 0\n",
    "next_business_index = 0\n",
    "\n",
    "# 최종 데이터를 리스트에 저장\n",
    "sort_data = []\n",
    "\n",
    "# JSON 파일을 읽고 처리\n",
    "with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "    for line in json_file:\n",
    "        data = json.loads(line)\n",
    "        user_id = data['user_id']\n",
    "        business_id = data['business_id']\n",
    "\n",
    "        # 유저 ID 매핑 업데이트\n",
    "        if user_id not in user_id_mapping:\n",
    "            user_id_mapping[user_id] = next_user_index\n",
    "            next_user_index += 1\n",
    "        # 비즈니스 ID 매핑 업데이트\n",
    "        if business_id not in business_id_mapping:\n",
    "            business_id_mapping[business_id] = next_business_index\n",
    "            next_business_index += 1\n",
    "\n",
    "        # 매핑된 ID로 데이터 저장\n",
    "        sort_data.append([user_id_mapping[user_id], business_id_mapping[business_id]])\n",
    "\n",
    "# 데이터를 정렬하고 새 파일에 저장\n",
    "sort_data.sort(key=lambda x: (x[0], x[1]))  # 먼저 user_id, 다음 business_id 기준으로 정렬\n",
    "\n",
    "print(\"모든 데이터가 user_id와 business_id를 기준으로 정렬되어 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b1806",
   "metadata": {},
   "source": [
    "리뷰가 10개 이상인 유저만 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07c1d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id  business_id\n",
      "0              0            0\n",
      "1              0          473\n",
      "2              0          927\n",
      "3              0        15261\n",
      "4              0        15753\n",
      "...          ...          ...\n",
      "6648468  1676360       114399\n",
      "6648469  1676360       114399\n",
      "6648470  1676360       114399\n",
      "6648471  1676360       114399\n",
      "6648472  1676360       114399\n",
      "\n",
      "[3303811 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# sort_data DataFrame으로 변환\n",
    "sort_data = pd.DataFrame(sort_data, columns=['user_id', 'business_id'])\n",
    "\n",
    "# 각 ID의 출현 빈도를 계산\n",
    "frequency = sort_data['user_id'].value_counts()\n",
    "\n",
    "# 출현 빈도가 10 이상인 ID만 필터링\n",
    "valid_ids = frequency[frequency >= 10].index\n",
    "\n",
    "# 필터링된 ID에 해당하는 데이터만 선택\n",
    "filtered_data = sort_data[sort_data['user_id'].isin(valid_ids)]\n",
    "\n",
    "# 혹은 출력하여 확인\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ea305",
   "metadata": {},
   "source": [
    "user_id, business_id 인덱스 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be5e60e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17096\\3316432536.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['user_id'] = filtered_data['user_id'].map(user_id_mapping)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17096\\3316432536.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['business_id'] = filtered_data['business_id'].map(business_id_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id  business_id\n",
      "0              0            0\n",
      "1              0          471\n",
      "2              0          923\n",
      "3              0        14710\n",
      "4              0        15202\n",
      "...          ...          ...\n",
      "6474055   117367       132905\n",
      "6474056   117367       133473\n",
      "6507832   117368        98751\n",
      "6507833   117368       134923\n",
      "6648457   117369       110433\n",
      "\n",
      "[3126989 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 유저 ID에 대해 고유한 ID를 정렬된 리스트로 추출하고 0부터 시작하는 새로운 인덱스를 매핑\n",
    "unique_user_ids = sorted(filtered_data['user_id'].unique())\n",
    "user_id_mapping = {id: index for index, id in enumerate(unique_user_ids)}\n",
    "filtered_data['user_id'] = filtered_data['user_id'].map(user_id_mapping)\n",
    "\n",
    "# 비즈니스 ID에 대해 고유한 ID를 정렬된 리스트로 추출하고 0부터 시작하는 새로운 인덱스를 매핑\n",
    "unique_business_ids = sorted(filtered_data['business_id'].unique())\n",
    "business_id_mapping = {id: index for index, id in enumerate(unique_business_ids)}\n",
    "filtered_data['business_id'] = filtered_data['business_id'].map(business_id_mapping)\n",
    "\n",
    "# 중복 제거\n",
    "indexing_data = filtered_data.drop_duplicates(subset=['user_id', 'business_id'])\n",
    "\n",
    "# 최종 데이터 프레임 출력하여 확인\n",
    "print(indexing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4960e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train.csv'와 'test.csv' 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# drop_duplicates 함수를 사용하여, 각 사용자 ID와 아이템 ID 조합의 첫 번째 등장만 유지합니다.\n",
    "first_data = indexing_data.drop_duplicates(subset=['user_id', 'business_id'])\n",
    "\n",
    "# 각 사용자별로 첫 번째 데이터를 테스트 데이터로, 나머지를 트레이닝 데이터로 분리\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# 사용자별로 그룹화하여 처리\n",
    "for user_id, group in indexing_data.groupby('user_id'):\n",
    "    test_data.append(group.iloc[0].tolist())  # 첫 번째 행을 테스트 데이터에 추가, 리스트로 변환\n",
    "    train_data.extend(group.iloc[1:].values.tolist())  # 나머지 행을 트레이닝 데이터에 추가, 리스트로 변환\n",
    "\n",
    "# 리스트를 DataFrame으로 변환\n",
    "train_df = pd.DataFrame(train_data, columns=['user_id', 'business_id'])\n",
    "test_df = pd.DataFrame(test_data, columns=['user_id', 'business_id'])\n",
    "\n",
    "# CSV 파일로 저장\n",
    "train_df.to_csv(path + 'train.csv', index=False, header=False, sep = '\\t')\n",
    "test_df.to_csv(path + 'test.csv', index=False, header=False, sep = '\\t')\n",
    "\n",
    "print(\"'train.csv'와 'test.csv' 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d36fc120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_neg 파일이 생성되었습니다\n"
     ]
    }
   ],
   "source": [
    "# 유저와 아이템 집합 구하기\n",
    "users = indexing_data['user_id'].unique()\n",
    "businesses = indexing_data['business_id'].unique()\n",
    "\n",
    "# 결과를 저장할 딕셔너리\n",
    "neg_dict = {}\n",
    "\n",
    "# 각 유저마다 가지고 있지 않은 아이템 찾기\n",
    "for user in users:\n",
    "    # 현재 유저가 가진 아이템\n",
    "    user_businesses = indexing_data[indexing_data['user_id'] == user]['business_id'].unique()\n",
    "    # 가지고 있지 않은 아이템\n",
    "    not_having_businesses = np.setdiff1d(businesses, user_businesses)\n",
    "    # 가지고 있지 않은 아이템 중에서 랜덤하게 100개 선택\n",
    "    if len(not_having_businesses) > 100:\n",
    "        sampled_businesses = np.random.choice(not_having_businesses, 100, replace=False)\n",
    "    else:\n",
    "        sampled_businesses = not_having_businesses\n",
    "    # 각 항목을 문자열로 변환 후 결과 딕셔너리에 저장\n",
    "    neg_dict[user] = ','.join([str(item) for item in sampled_businesses])\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "with open('test_neg.csv', 'w') as f:\n",
    "    for user, businesses in neg_dict.items():\n",
    "        f.write(f\"{businesses}\\n\")\n",
    "        \n",
    "        \n",
    "print(\"text_neg 파일이 생성되었습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3015fa82",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './test/test_neg.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 필요한 파일을 읽고 쓰기 위해 open 함수를 사용\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_neg.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m neg_file, \u001b[38;5;28mopen\u001b[39m(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m test_file, \u001b[38;5;28mopen\u001b[39m(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_neg_100.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m result_file:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# 파일에서 각 줄을 읽음\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     neg_lines \u001b[38;5;241m=\u001b[39m neg_file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m      5\u001b[0m     test_lines \u001b[38;5;241m=\u001b[39m test_file\u001b[38;5;241m.\u001b[39mreadlines()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './test/test_neg.csv'"
     ]
    }
   ],
   "source": [
    "# 필요한 파일을 읽고 쓰기 위해 open 함수를 사용\n",
    "with open(path + 'test_neg.csv', 'r') as neg_file, open(path + 'test.csv', 'r') as test_file, open(path + 'test_neg_100.csv', 'w') as result_file:\n",
    "    # 파일에서 각 줄을 읽음\n",
    "    neg_lines = neg_file.readlines()\n",
    "    test_lines = test_file.readlines()\n",
    "    \n",
    "    # neg_lines와 test_lines의 길이가 같다고 가정하고, 각 줄을 합침\n",
    "    for neg_line, test_line in zip(neg_lines, test_lines):\n",
    "        # test_line에서 데이터를 추출하여 형식을 맞춤\n",
    "        test_index, test_value = test_line.strip().split(',')\n",
    "        test_tuple = f'({test_index},{test_value})'\n",
    "        \n",
    "        # neg_line에서 쉼표를 탭으로 변환\n",
    "        neg_data = '\\t'.join(neg_line.strip().split(','))\n",
    "        \n",
    "        # 결과를 파일에 쓰기\n",
    "        result_line = test_tuple + '\\t' + neg_data.strip() + '\\n'\n",
    "        result_file.write(result_line)\n",
    "\n",
    "# 결과 파일인 'result.txt'가 생성되고 원하는 형태로 데이터가 저장됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6442fd-6f12-47ee-915c-499af73c3356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 파일 로드\n",
    "# df = pd.read_csv('pos.txt', header=None, names=['user_id', 'business_id'])\n",
    "\n",
    "# # 각 사용자가 가진 아이템의 집합을 만듭니다.\n",
    "# user_items = df.groupby('user_id')['business_id'].apply(set)\n",
    "\n",
    "# # 전체 아이템 집합\n",
    "# all_items = set(df['business_id'])\n",
    "\n",
    "# # 각 사용자별로 가지고 있지 않은 아이템을 찾아 랜덤하게 100개 선택\n",
    "# results = {}\n",
    "# for user, items in user_items.items():\n",
    "#     not_owned_items = list(all_items - items)\n",
    "#     if len(not_owned_items) > 100:\n",
    "#         selected_items = np.random.choice(not_owned_items, 100, replace=False)\n",
    "#     else:\n",
    "#         selected_items = not_owned_items\n",
    "#     results[user] = selected_items\n",
    "\n",
    "# # 결과를 파일로 저장, 사용자 ID 없이 아이템만 저장\n",
    "# with open('neg_100.txt', 'w') as file:\n",
    "#     for items in results.values():\n",
    "#         items_str = ','.join(map(str, items))\n",
    "#         file.write(f\"{items_str}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
