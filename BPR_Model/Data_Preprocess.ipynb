{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21166128-d366-4bb6-8b2a-c910d7ce9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "path = './dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c468b5",
   "metadata": {},
   "source": [
    "## Test 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a552bb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkin_data 생성 완료.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# JSON 파일 경로\n",
    "json_file_path = path + 'review.json'\n",
    "\n",
    "# CSV 파일 경로\n",
    "csv_file_path = path + 'checkin.csv'\n",
    "\n",
    "# CSV 파일을 쓰기 모드로 열기\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    # CSV 라이터 생성\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # CSV 파일 헤더 작성\n",
    "    csv_writer.writerow(['user_id', 'business_id'])\n",
    "\n",
    "    # JSON 파일을 한 줄씩 읽어서 처리\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "        for line in json_file:\n",
    "            data = json.loads(line)  # JSON 데이터 파싱\n",
    "            # user_id와 business_id 추출\n",
    "            user_id = data['user_id']\n",
    "            business_id = data['business_id']\n",
    "\n",
    "            # CSV 파일에 데이터 작성\n",
    "            csv_writer.writerow([user_id, business_id])\n",
    "\n",
    "print(\"checkin_data 생성 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902b7371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[156830, '---kPU91CF4Lq2-WlRu9Lw'], [209756, '---kPU91CF4Lq2-WlRu9Lw'], [213557, '---kPU91CF4Lq2-WlRu9Lw']]\n",
      "[[156830, 0], [209756, 0], [213557, 0]]\n",
      "[[0, 100781], [1, 3783], [1, 5256]]\n",
      "CSV 파일이 user_id를 기준으로 정렬되었고, 새로운 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 경로\n",
    "input_file = path + 'checkin.csv'\n",
    "output_file = path +  'checkin_data_Yelp.csv'\n",
    "\n",
    "# CSV 파일을 읽고 데이터를 리스트로 저장\n",
    "data = []\n",
    "with open(input_file, 'r', newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    header = next(csv_reader)  # 헤더 행\n",
    "    #data.append(header)\n",
    "    for row in csv_reader:\n",
    "        data.append(row)\n",
    "\n",
    "# user_id를 기준으로 데이터를 정렬\n",
    "data.sort(key=lambda x: x[0])  # 여기서 0은 user_id 열을 가리킵니다. 0부터 시작하면 첫 번째 열입니다.\n",
    "\n",
    "# user_id를 정수형으로 변환\n",
    "idx = 0\n",
    "before_user_id = data[0][0]\n",
    "for i in data:\n",
    "  if i[0] == before_user_id:\n",
    "    i[0] = idx\n",
    "  else:\n",
    "    idx += 1\n",
    "    before_user_id = i[0]\n",
    "    i[0] = idx\n",
    "\n",
    "# business_id 기준으로 데이터를 정렬\n",
    "data.sort(key=lambda x: x[1])  # 여기서 0은 user_id 열을 가리킵니다. 0부터 시작하면 첫 번째 열입니다.\n",
    "print(data[:3])\n",
    "\n",
    "# business_id 정수형으로 변환\n",
    "idx = 0\n",
    "before_business_id = data[0][1]\n",
    "for i in data:\n",
    "  if i[1] == before_business_id:\n",
    "    i[1] = idx\n",
    "  else:\n",
    "    idx += 1\n",
    "    before_business_id = i[1]\n",
    "    i[1] = idx\n",
    "\n",
    "print(data[:3])\n",
    "\n",
    "# 다시 유저 번호 기준으로 정렬\n",
    "data.sort(key=lambda x: x[0])\n",
    "print(data[:3])\n",
    "\n",
    "# 정렬된 데이터를 새로운 파일에 저장\n",
    "with open(output_file, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(\"CSV 파일이 user_id를 기준으로 정렬되었고, 새로운 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07c1d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID   Value\n",
      "1              1    3783\n",
      "2              1    5256\n",
      "3              1    5256\n",
      "4              1    5256\n",
      "5              1   10914\n",
      "...          ...     ...\n",
      "6990271  1987924   96954\n",
      "6990272  1987924   98187\n",
      "6990273  1987924  107385\n",
      "6990274  1987924  120353\n",
      "6990275  1987924  127628\n",
      "\n",
      "[3303811 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 파일로부터 데이터를 읽기\n",
    "# 이 코드에서는 파일 경로 'checkin_data.txt'로 가정합니다.\n",
    "df = pd.read_csv(path + 'checkin_data_Yelp.csv', header=None, names=['ID', 'Value'])\n",
    "\n",
    "# 각 ID의 출현 빈도를 계산\n",
    "frequency = df['ID'].value_counts()\n",
    "\n",
    "# 출현 빈도가 10 이상인 ID만 필터링\n",
    "valid_ids = frequency[frequency >= 10].index\n",
    "\n",
    "# 필터링된 ID에 해당하는 데이터만 선택\n",
    "filtered_df = df[df['ID'].isin(valid_ids)]\n",
    "\n",
    "# 결과를 새 파일로 저장하거나 출력\n",
    "filtered_df.to_csv(path + 'filtered_data.csv', index=False, header=False)\n",
    "# 혹은 출력하여 확인\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c1e295b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID   Value\n",
      "0             0    3783\n",
      "1             0    5256\n",
      "2             0    5256\n",
      "3             0    5256\n",
      "4             0   10914\n",
      "...         ...     ...\n",
      "3303806  117369   96954\n",
      "3303807  117369   98187\n",
      "3303808  117369  107385\n",
      "3303809  117369  120353\n",
      "3303810  117369  127628\n",
      "\n",
      "[3303811 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 파일로부터 데이터를 읽기\n",
    "df = pd.read_csv(path + 'filtered_data.csv', header=None, names=['ID', 'Value'])\n",
    "\n",
    "# 고유한 ID를 정렬된 리스트로 추출합니다.\n",
    "unique_ids = sorted(df['ID'].unique())\n",
    "\n",
    "# 고유 ID에 대해 0부터 시작하는 새로운 인덱스를 매핑합니다.\n",
    "id_mapping = {id: index for index, id in enumerate(unique_ids)}\n",
    "\n",
    "# 이 매핑을 사용하여 모든 ID 값을 업데이트합니다.\n",
    "df['ID'] = df['ID'].map(id_mapping)\n",
    "\n",
    "# 결과 확인\n",
    "print(df)\n",
    "\n",
    "# 결과를 파일로 저장할 수 있습니다.\n",
    "df.to_csv(path + 'reindexed_data.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d65ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID   Value\n",
      "0             0    3655\n",
      "1             0    5073\n",
      "2             0    5073\n",
      "3             0    5073\n",
      "4             0   10518\n",
      "...         ...     ...\n",
      "3303806  117369   93529\n",
      "3303807  117369   94718\n",
      "3303808  117369  103572\n",
      "3303809  117369  116066\n",
      "3303810  117369  123074\n",
      "\n",
      "[3303811 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 파일로부터 데이터를 읽기\n",
    "df = pd.read_csv(path + 'reindexed_data.csv', header=None, names=['ID', 'Value'])\n",
    "\n",
    "# 고유한 ID를 정렬된 리스트로 추출합니다.\n",
    "unique_ids = sorted(df['Value'].unique())\n",
    "\n",
    "# 고유 ID에 대해 0부터 시작하는 새로운 인덱스를 매핑합니다.\n",
    "id_mapping = {id: index for index, id in enumerate(unique_ids)}\n",
    "\n",
    "# 이 매핑을 사용하여 모든 ID 값을 업데이트합니다.\n",
    "df['Value'] = df['Value'].map(id_mapping)\n",
    "\n",
    "# 결과 확인\n",
    "print(df)\n",
    "\n",
    "df = df.drop_duplicates(subset=['ID', 'Value'])\n",
    "\n",
    "# 결과를 파일로 저장할 수 있습니다.\n",
    "df.to_csv(path + 'pos.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4960e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved: 'train.csv' and 'test.csv'\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로딩\n",
    "data = pd.read_csv(path + 'pos.csv', header=None, names=['user_id', 'item_id'])\n",
    "\n",
    "# 중복 제거\n",
    "# drop_duplicates 함수를 사용하여, 각 사용자 ID와 아이템 ID 조합의 첫 번째 등장만 유지합니다.\n",
    "data = data.drop_duplicates(subset=['user_id', 'item_id'])\n",
    "\n",
    "# 각 사용자별로 첫 번째 데이터를 테스트 데이터로, 나머지를 트레이닝 데이터로 분리\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# 사용자별로 그룹화하여 처리\n",
    "for user_id, group in data.groupby('user_id'):\n",
    "    test_data.append(group.iloc[0].tolist())  # 첫 번째 행을 테스트 데이터에 추가, 리스트로 변환\n",
    "    train_data.extend(group.iloc[1:].values.tolist())  # 나머지 행을 트레이닝 데이터에 추가, 리스트로 변환\n",
    "\n",
    "# 리스트를 DataFrame으로 변환\n",
    "train_df = pd.DataFrame(train_data, columns=['user_id', 'item_id'])\n",
    "test_df = pd.DataFrame(test_data, columns=['user_id', 'item_id'])\n",
    "\n",
    "# CSV 파일로 저장\n",
    "train_df.to_csv(path + 'train.csv', index=False, header=False)\n",
    "test_df.to_csv(path + 'test.csv', index=False, header=False)\n",
    "\n",
    "print(\"Files saved: 'train.csv' and 'test.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3015fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 파일을 읽고 쓰기 위해 open 함수를 사용\n",
    "with open(path + 'neg_100.txt', 'r') as neg_file, open(path + 'test.csv', 'r') as test_file, open(path + 'test_neg_100.csv', 'w') as result_file:\n",
    "    # 파일에서 각 줄을 읽음\n",
    "    neg_lines = neg_file.readlines()\n",
    "    test_lines = test_file.readlines()\n",
    "    \n",
    "    # neg_lines와 test_lines의 길이가 같다고 가정하고, 각 줄을 합침\n",
    "    for neg_line, test_line in zip(neg_lines, test_lines):\n",
    "        # test_line에서 데이터를 추출하여 형식을 맞춤\n",
    "        test_index, test_value = test_line.strip().split(',')\n",
    "        test_tuple = f'({test_index},{test_value})'\n",
    "        \n",
    "        # neg_line에서 쉼표를 탭으로 변환\n",
    "        neg_data = '\\t'.join(neg_line.strip().split(','))\n",
    "        \n",
    "        # 결과를 파일에 쓰기\n",
    "        result_line = test_tuple + '\\t' + neg_data.strip() + '\\n'\n",
    "        result_file.write(result_line)\n",
    "\n",
    "# 결과 파일인 'result.txt'가 생성되고 원하는 형태로 데이터가 저장됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6442fd-6f12-47ee-915c-499af73c3356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 파일 로드\n",
    "df = pd.read_csv('pos.txt', header=None, names=['user', 'item'])\n",
    "\n",
    "# 각 사용자가 가진 아이템의 집합을 만듭니다.\n",
    "user_items = df.groupby('user')['item'].apply(set)\n",
    "\n",
    "# 전체 아이템 집합\n",
    "all_items = set(df['item'])\n",
    "\n",
    "# 각 사용자별로 가지고 있지 않은 아이템을 찾아 랜덤하게 100개 선택\n",
    "results = {}\n",
    "for user, items in user_items.items():\n",
    "    not_owned_items = list(all_items - items)\n",
    "    if len(not_owned_items) > 100:\n",
    "        selected_items = np.random.choice(not_owned_items, 100, replace=False)\n",
    "    else:\n",
    "        selected_items = not_owned_items\n",
    "    results[user] = selected_items\n",
    "\n",
    "# 결과를 파일로 저장, 사용자 ID 없이 아이템만 저장\n",
    "with open('neg_100.txt', 'w') as file:\n",
    "    for items in results.values():\n",
    "        items_str = ','.join(map(str, items))\n",
    "        file.write(f\"{items_str}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
