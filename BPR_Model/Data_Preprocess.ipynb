{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21166128-d366-4bb6-8b2a-c910d7ce9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "json_path = './yelp/'\n",
    "data_path = './dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c468b5",
   "metadata": {},
   "source": [
    "## Review 데이터 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4fb919",
   "metadata": {},
   "source": [
    "user_id 및 business_id 추출, 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca32dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로 설정\n",
    "json_file_path = json_path + 'review.json'\n",
    "\n",
    "# 유저 ID와 비즈니스 ID를 매핑하기 위한 딕셔너리\n",
    "user_id_mapping = {}\n",
    "business_id_mapping = {}\n",
    "next_user_index = 0\n",
    "next_business_index = 0\n",
    "\n",
    "# 최종 데이터를 리스트에 저장\n",
    "sort_data = []\n",
    "\n",
    "# JSON 파일을 읽고 처리\n",
    "with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "    for line in json_file:\n",
    "        data = json.loads(line)\n",
    "        user_id = data['user_id']\n",
    "        business_id = data['business_id']\n",
    "\n",
    "        # 유저 ID 매핑 업데이트\n",
    "        if user_id not in user_id_mapping:\n",
    "            user_id_mapping[user_id] = next_user_index\n",
    "            next_user_index += 1\n",
    "        # 비즈니스 ID 매핑 업데이트\n",
    "        if business_id not in business_id_mapping:\n",
    "            business_id_mapping[business_id] = next_business_index\n",
    "            next_business_index += 1\n",
    "\n",
    "        # 매핑된 ID로 데이터 저장\n",
    "        sort_data.append([user_id_mapping[user_id], business_id_mapping[business_id]])\n",
    "\n",
    "# 데이터를 정렬하고 새 파일에 저장\n",
    "sort_data.sort(key=lambda x: (x[0], x[1]))  # 먼저 user_id, 다음 business_id 기준으로 정렬\\\n",
    "\n",
    "print(\"모든 데이터가 user_id와 business_id를 기준으로 정렬되어 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f42a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sort_data.columns:\n",
    "    unique_count = sort_data[column].nunique()\n",
    "    max_value = sort_data[column].max()\n",
    "    min_value = sort_data[column].min()\n",
    "    \n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"  Unique Values: {unique_count}\")\n",
    "    print(f\"  Max Value: {max_value}\")\n",
    "    print(f\"  Min Value: {min_value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aacca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필라델피아에 있는 비즈니스 ID를 추출하기 위한 파일 경로\n",
    "business_json_path = json_path + 'business.json'\n",
    "\n",
    "# 필라델피아 비즈니스 ID 저장을 위한 세트\n",
    "philadelphia_business_ids = set()\n",
    "\n",
    "# business.json 파일 읽기\n",
    "with open(business_json_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        business_data = json.loads(line)\n",
    "        if business_data['city'] == 'Philadelphia':\n",
    "            philadelphia_business_ids.add(business_data['business_id'])\n",
    "\n",
    "# 필라델피아 비즈니스 리뷰만 포함하는 데이터 추출\n",
    "philadelphia_sort_data = [\n",
    "    [user_id, business_id] for user_id, business_id in sort_data\n",
    "    if business_id_mapping.get(business_id) in philadelphia_business_ids\n",
    "]\n",
    "\n",
    "# 필요하다면 philadelphia_sort_data를 파일에 저장할 수 있습니다.\n",
    "\n",
    "print(\"필라델피아의 비즈니스 리뷰 데이터가 준비되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b1806",
   "metadata": {},
   "source": [
    "리뷰가 10개 이상인 유저만 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c1d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_data DataFrame으로 변환\n",
    "sort_data = pd.DataFrame(sort_data, columns=['user_id', 'business_id'])\n",
    "\n",
    "# 각 ID의 출현 빈도를 계산\n",
    "frequency = sort_data['user_id'].value_counts()\n",
    "\n",
    "# 출현 빈도가 10 이상인 ID만 필터링\n",
    "valid_ids = frequency[frequency >= 10].index\n",
    "\n",
    "# 필터링된 ID에 해당하는 데이터만 선택\n",
    "filtered_data = sort_data[sort_data['user_id'].isin(valid_ids)]\n",
    "\n",
    "# 혹은 출력하여 확인\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ea305",
   "metadata": {},
   "source": [
    "user_id, business_id 인덱스 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "philadelphia = []\n",
    "\n",
    "# business.json 파일 읽기\n",
    "with open(business_json_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        business_data = json.loads(line)\n",
    "        if business_data['city'] == 'Philadelphia':\n",
    "            philadelphia_business_id = business_data['business_id']\n",
    "            philadelphia_latitude = business_data['latitude']\n",
    "            philadelphia_longitude = business_data['longitude']\n",
    "            philadelphia.append({'business_id': philadelphia_business_id, \n",
    "                                 'latitude': philadelphia_latitude, \n",
    "                                 'longitude': philadelphia_longitude})\n",
    "\n",
    "philadelphia = pd.DataFrame(philadelphia)\n",
    "\n",
    "philadelphia['business_id'] = philadelphia['business_id'].map(business_id_mapping)\n",
    "\n",
    "# 유저 ID에 대해 고유한 ID를 정렬된 리스트로 추출하고 0부터 시작하는 새로운 인덱스를 매핑\n",
    "unique_user_ids = sorted(filtered_data['user_id'].unique())\n",
    "user_id_mapping = {id: index for index, id in enumerate(unique_user_ids)}\n",
    "filtered_data['user_id'] = filtered_data['user_id'].map(user_id_mapping)\n",
    "\n",
    "# 비즈니스 ID에 대해 고유한 ID를 정렬된 리스트로 추출하고 0부터 시작하는 새로운 인덱스를 매핑\n",
    "print(filtered_data)\n",
    "unique_business_ids = sorted(filtered_data['business_id'].unique())\n",
    "business_id_mapping_uni = {id: index for index, id in enumerate(unique_business_ids)}\n",
    "filtered_data['business_id'] = filtered_data['business_id'].map(business_id_mapping_uni)\n",
    "\n",
    "philadelphia['business_id'] = philadelphia['business_id'].map(business_id_mapping)\n",
    "\n",
    "# CSV로 저장\n",
    "philadelphia.to_csv('poi.csv', index=False, header=False, sep = '\\t')\n",
    "\n",
    "# 중복 제거\n",
    "indexing_data = filtered_data.drop_duplicates(subset=['user_id', 'business_id'])\n",
    "\n",
    "# # 최종 데이터 프레임 출력하여 확인\n",
    "# print(indexing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in filtered_data.columns:\n",
    "    unique_count = filtered_data[column].nunique()\n",
    "    max_value = filtered_data[column].max()\n",
    "    min_value = filtered_data[column].min()\n",
    "    \n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"  Unique Values: {unique_count}\")\n",
    "    print(f\"  Max Value: {max_value}\")\n",
    "    print(f\"  Min Value: {min_value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자별 데이터 개수를 계산하여 10개 이상인지 확인하는 함수\n",
    "def check_data_count(data):\n",
    "    # 사용자별 데이터 개수 계산\n",
    "    user_data_count = data['user_id'].value_counts()\n",
    "    \n",
    "    # 데이터 개수가 10개 이상인 사용자 ID 필터링\n",
    "    users_with_10_or_more_data = user_data_count[user_data_count < 2].index.tolist()\n",
    "    \n",
    "    return users_with_10_or_more_data\n",
    "\n",
    "# 10개 이상의 데이터가 있는 사용자 확인\n",
    "users_with_10_or_more_data = check_data_count(filtered_data)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"데이터가 10개 이상인 사용자 ID:\", users_with_10_or_more_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506279b7",
   "metadata": {},
   "source": [
    "train 및 test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4960e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train.csv'와 'test.csv' 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# drop_duplicates 함수를 사용하여, 각 사용자 ID와 아이템 ID 조합의 첫 번째 등장만 유지합니다.\n",
    "#first_data = indexing_data.drop_duplicates(subset=['user_id', 'business_id'])\n",
    "\n",
    "# 각 사용자별로 첫 번째 데이터를 테스트 데이터로, 나머지를 트레이닝 데이터로 분리\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# 사용자별로 그룹화하여 처리\n",
    "for user_id, group in filtered_data.groupby('user_id'):\n",
    "    test_data.append(group.iloc[0].tolist())  # 첫 번째 행을 테스트 데이터에 추가, 리스트로 변환\n",
    "    train_data.extend(group.iloc[1:].values.tolist())  # 나머지 행을 트레이닝 데이터에 추가, 리스트로 변환\n",
    "\n",
    "# 리스트를 DataFrame으로 변환\n",
    "train_df = pd.DataFrame(train_data, columns=['user_id', 'business_id'])\n",
    "test_df = pd.DataFrame(test_data, columns=['user_id', 'business_id'])\n",
    "\n",
    "# CSV 파일로 저장\n",
    "train_df.to_csv(data_path + 'train.csv', index=False, header=False, sep = '\\t')\n",
    "test_df.to_csv(data_path + 'test.csv', index=False, header=False, sep = '\\t')\n",
    "\n",
    "\n",
    "print(\"'train.csv'와 'test.csv' 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "613a8259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: user_id\n",
      "  Unique Values: 117370\n",
      "  Max Value: 117369\n",
      "  Min Value: 0\n",
      "\n",
      "Column: business_id\n",
      "  Unique Values: 17075\n",
      "  Max Value: 110433\n",
      "  Min Value: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in train_df.columns:\n",
    "    unique_count = test_df[column].nunique()\n",
    "    max_value = test_df[column].max()\n",
    "    min_value = test_df[column].min()\n",
    "    \n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"  Unique Values: {unique_count}\")\n",
    "    print(f\"  Max Value: {max_value}\")\n",
    "    print(f\"  Min Value: {min_value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c3952ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: user_id\n",
      "  Unique Values: 117370\n",
      "  Max Value: 117369\n",
      "  Min Value: 0\n",
      "\n",
      "Column: business_id\n",
      "  Unique Values: 144610\n",
      "  Max Value: 144905\n",
      "  Min Value: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in train_df.columns:\n",
    "    unique_count = train_df[column].nunique()\n",
    "    max_value = train_df[column].max()\n",
    "    min_value = train_df[column].min()\n",
    "    \n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"  Unique Values: {unique_count}\")\n",
    "    print(f\"  Max Value: {max_value}\")\n",
    "    print(f\"  Min Value: {min_value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5150d",
   "metadata": {},
   "source": [
    "negative 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d36fc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저와 아이템 집합 구하기\n",
    "users = filtered_data['user_id'].unique()\n",
    "businesses = filtered_data['business_id'].unique()\n",
    "\n",
    "# 결과를 저장할 딕셔너리\n",
    "neg_dict = {}\n",
    "\n",
    "# 각 유저마다 가지고 있지 않은 아이템 찾기\n",
    "for user in users:\n",
    "    user_businesses = filtered_data[filtered_data['user_id'] == user]['business_id'].unique()\n",
    "    not_having_businesses = np.setdiff1d(businesses, user_businesses)\n",
    "    if len(not_having_businesses) > 100:\n",
    "        sampled_businesses = np.random.choice(not_having_businesses, 100, replace=False)\n",
    "    else:\n",
    "        sampled_businesses = not_having_businesses\n",
    "    neg_dict[user] = ','.join([str(item) for item in sampled_businesses])\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "with open(data_path + 'test_neg.csv', 'w') as f:\n",
    "    for user, businesses in neg_dict.items():\n",
    "        f.write(f\"{businesses}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9690b8c",
   "metadata": {},
   "source": [
    "negative 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3015fa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 'test_neg_100.csv'가 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 파일을 읽고 쓰기 위해 open 함수를 사용\n",
    "with open(data_path + 'test_neg.csv', 'r') as neg_file, open(data_path + 'test.csv', 'r') as test_file, open(data_path + 'test_neg_100.csv', 'w') as result_file:\n",
    "    neg_lines = neg_file.readlines()\n",
    "    test_lines = test_file.readlines()\n",
    "    \n",
    "    for neg_line, test_line in zip(neg_lines, test_lines):\n",
    "        user_id, neg_data = neg_line.strip().split(',', 1)\n",
    "        test_index, test_value = test_line.strip().split('\\t')\n",
    "        test_tuple = f'({test_index},{test_value})'\n",
    "        \n",
    "        neg_data_formatted = '\\t'.join(neg_data.split(','))\n",
    "        \n",
    "        result_line = test_tuple + '\\t' + neg_data_formatted + '\\n'\n",
    "        result_file.write(result_line)\n",
    "\n",
    "print(\"파일 'test_neg_100.csv'가 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f34a8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: UserID\n",
      "  Unique Values: 6040\n",
      "  Max Value: 6039\n",
      "  Min Value: 0\n",
      "\n",
      "Column: MovieID\n",
      "  Unique Values: 3704\n",
      "  Max Value: 3705\n",
      "  Min Value: 0\n",
      "\n",
      "Column: Rating\n",
      "  Unique Values: 5\n",
      "  Max Value: 5\n",
      "  Min Value: 1\n",
      "\n",
      "Column: Timestamp\n",
      "  Unique Values: 455111\n",
      "  Max Value: 1046454548\n",
      "  Min Value: 956703932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 파일 경로\n",
    "file_path = \"./dataset/ml-1m.train.rating\"\n",
    "\n",
    "# 탭으로 구분된 데이터를 읽어와 데이터프레임으로 저장\n",
    "df = pd.read_csv(file_path, sep='\\t', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "\n",
    "for column in df.columns:\n",
    "    unique_count = df[column].nunique()\n",
    "    max_value = df[column].max()\n",
    "    min_value = df[column].min()\n",
    "    \n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"  Unique Values: {unique_count}\")\n",
    "    print(f\"  Max Value: {max_value}\")\n",
    "    print(f\"  Min Value: {min_value}\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
