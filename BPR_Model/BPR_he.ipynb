{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51a2a48-5c9f-49c8-b812-c180aac6260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/hexiangnan/theano-BPR/blob/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e63c2b-9166-4083-9222-92908c3ead26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "\n",
    "import math\n",
    "import heapq\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e9f0d5-e9c8-45ef-a138-3929e803f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFbpr(object):\n",
    "\n",
    "    def __init__(self, train, test, num_user, num_item, \n",
    "                 factors, learning_rate, reg, init_mean, init_stdev):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.num_user = num_user\n",
    "        self.num_item = num_item\n",
    "        self.factors = factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg = reg\n",
    "        self.init_mean = init_mean\n",
    "        self.init_stdev = init_stdev\n",
    "        \n",
    "        # user & item latent vectors\n",
    "        self.U = torch.normal(mean = self.init_mean * torch.ones(self.num_user, self.factors), std = self.init_stdev).requires_grad_()\n",
    "        self.V = torch.normal(mean = self.init_mean * torch.ones(self.num_item, self.factors), std = self.init_stdev).requires_grad_()\n",
    "\n",
    "        # optim\n",
    "        self.mf_optim = optim.Adam([self.U, self.V], lr=self.learning_rate)\n",
    "        # self.mf_scheduler = optim.lr_scheduler.MultiStepLR(self.mf_optim, [30, 200], 0.1)\n",
    "        # Each element is the set of items for a user, used for negative sampling\n",
    "        self.items_of_user = []\n",
    "        self.num_rating = 0     # number of ratings\n",
    "        for u in range(len(self.train)):  # xrange를 range로 수정\n",
    "            self.items_of_user.append(set([]))  # sets 모듈을 사용하는 대신 set을 직접 사용\n",
    "            for i in range(len(self.train[u])):  # xrange를 range로 수정\n",
    "                item = self.train[u][i][0]\n",
    "                self.items_of_user[u].add(item)\n",
    "                self.num_rating += 1\n",
    "\n",
    "\n",
    "    def forward(self, u, i, j):\n",
    "        '''\n",
    "        Args:\n",
    "            u: user id. type=int or list.\n",
    "            i: positive item id. type=int or list.\n",
    "            j: negative item id. type=int or list.\n",
    "\n",
    "        Returns:\n",
    "            y_ui: predicted score between user and positive item.\n",
    "            y_uj: predicted score between user and negative item.\n",
    "            loss: BPR loss. It is the opposite of BPR-OPT.\n",
    "        '''\n",
    "        y_ui = torch.diag(torch.mm(self.U[u], self.V[i].t()))\n",
    "        y_uj = torch.diag(torch.mm(self.U[u], self.V[j].t()))\n",
    "        regularizer = self.reg * (torch.sum(self.U[u] ** 2) + torch.sum(self.V[i] ** 2) + torch.sum(self.V[j] ** 2))\n",
    "        loss = regularizer - torch.sum(torch.log2(torch.sigmoid(y_ui - y_uj)))\n",
    "        return y_ui, y_uj, loss\n",
    "\n",
    "    def build_model(self, maxIter=100, num_thread=4, batch_size=32):\n",
    "        # Training process\n",
    "        print(\"Training MF-BPR with: learning_rate=%.2f, regularization=%.4f, factors=%d, #epoch=%d, batch_size=%d.\"\n",
    "              %(self.learning_rate, self.reg, self.factors, maxIter, batch_size))\n",
    "        for iteration in range(maxIter):    \n",
    "            # Each training epoch\n",
    "            t1 = time.time()\n",
    "            for s in range(self.num_rating / batch_size):\n",
    "                # sample a batch of users, positive samples and negative samples \n",
    "                (users, items_pos, items_neg) = self.get_batch(batch_size)\n",
    "                # perform a batched SGD step\n",
    "                self.sgd_step(users, items_pos, items_neg, self.learning_rate)\n",
    "            \n",
    "            # check performance\n",
    "            t2 = time.time()\n",
    "            self.U_np = self.U.eval()\n",
    "            self.V_np = self.V.eval()\n",
    "            topK = 100\n",
    "            (hits, ndcgs) = evaluate_model(self, self.test, topK, num_thread)\n",
    "            print(\"Iter=%d [%.1f s] HitRatio@%d = %.3f, NDCG@%d = %.3f [%.1f s]\" \n",
    "                  %(iteration, t2-t1, topK, np.array(hits).mean(), topK, np.array(ndcgs).mean(), time.time()-t2))\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        return np.inner(self.U[u].detach().numpy(), self.V[i].detach().numpy())\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        users, pos_items, neg_items = [], [], []\n",
    "        for i in range(batch_size):  # xrange를 range로 수정\n",
    "            # sample a user\n",
    "            u = np.random.randint(0, self.num_user)\n",
    "            # sample a positive item\n",
    "            i = self.train[u][np.random.randint(0, len(self.train[u]))][0]\n",
    "            # sample a negative item\n",
    "            j = np.random.randint(0, self.num_item)\n",
    "            while j in self.items_of_user[u]:\n",
    "                j = np.random.randint(0, self.num_item)\n",
    "            users.append(u)\n",
    "            pos_items.append(i)\n",
    "            neg_items.append(j)\n",
    "        return (users, pos_items, neg_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aff8870-1628-4604-b1f7-d21462c94303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadRatingFile_HoldKOut(filename, splitter, K):\n",
    "    \"\"\"\n",
    "    Each line of .rating file is: userId(starts from 0), itemId, ratingScore, time\n",
    "    Each element of train is the [[item1, time1], [item2, time2] of the user, sorted by time\n",
    "    Each element of test is the [user, item, time] interaction, sorted by time\n",
    "    \"\"\"\n",
    "    train = []  \n",
    "    test = []\n",
    "    \n",
    "    # load ratings into train.\n",
    "    num_ratings = 0\n",
    "    num_item = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        next(f)\n",
    "        line = f.readline()\n",
    "        while line != None and line != \"\":\n",
    "            arr = line.split(splitter)\n",
    "            if (len(arr) < 4):\n",
    "                continue\n",
    "            user, item, time = int(arr[0]), int(arr[1]), int(arr[3]) \n",
    "            if (len(train) <= user):\n",
    "                train.append([])\n",
    "            train[user].append([item, time])\n",
    "            num_ratings += 1\n",
    "            num_item = max(item, num_item)\n",
    "            line = f.readline()\n",
    "    num_user = len(train)\n",
    "    num_item = num_item + 1\n",
    "    \n",
    "    # sort ratings of each user by time\n",
    "    def getTime(item):\n",
    "        return item[-1];\n",
    "    for u in range (len(train)):\n",
    "        train[u] = sorted(train[u], key = getTime)\n",
    "    \n",
    "    # split into train/test\n",
    "    for u in range (len(train)):\n",
    "        for k in range(K):\n",
    "            if (len(train[u]) == 0):\n",
    "                break\n",
    "            test.append([u, train[u][-1][0], train[u][-1][1]])\n",
    "            del train[u][-1]    # delete the last element from train\n",
    "            \n",
    "    # sort the test ratings by time\n",
    "    test = sorted(test, key = getTime)\n",
    "    \n",
    "    return train, test, num_user, num_item, num_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7351e6b-7938-4665-a54a-21c9a7a9bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables that are shared across processes\n",
    "_model = None\n",
    "_testRatings = None\n",
    "_K = None\n",
    "\n",
    "def evaluate_model(model, testRatings, K, num_thread):\n",
    "    \"\"\"\n",
    "    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation\n",
    "    Return: score of each test rating.\n",
    "    \"\"\"\n",
    "    global _model\n",
    "    global _testRatings\n",
    "    global _K\n",
    "    _model = model\n",
    "    _testRatings = testRatings\n",
    "    _K = K\n",
    "    num_rating = len(testRatings)\n",
    "    \n",
    "    pool = multiprocessing.Pool(processes=num_thread)\n",
    "    res = pool.map(eval_one_rating, range(num_rating))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    hits = [r[0] for r in res]\n",
    "    ndcgs = [r[1] for r in res]\n",
    "    return (hits, ndcgs)\n",
    "\n",
    "def eval_one_rating(idx):\n",
    "    rating = _testRatings[idx]\n",
    "    hr = ndcg = 0\n",
    "    u = rating[0]\n",
    "    gtItem = rating[1]\n",
    "    map_item_score = {}\n",
    "    # Get the score of the test item first\n",
    "    maxScore = _model.predict(u, gtItem)\n",
    "    # Early stopping if there are K items larger than maxScore.\n",
    "    countLarger = 0\n",
    "    for i in xrange(_model.num_item):\n",
    "        early_stop = False\n",
    "        score = _model.predict(u, i)\n",
    "        map_item_score[i] = score\n",
    "        \n",
    "        if score > maxScore:\n",
    "            countLarger += 1\n",
    "        if countLarger > _K:\n",
    "            hr = ndcg = 0\n",
    "            early_stop = True\n",
    "            break\n",
    "    # Generate topK rank list\n",
    "    if early_stop == False:\n",
    "        ranklist = heapq.nlargest(_K, map_item_score, key=map_item_score.get)\n",
    "        hr = getHitRatio(ranklist, gtItem)\n",
    "        ndcg = getNDCG(ranklist, gtItem)\n",
    "        \n",
    "    return (hr, ndcg)\n",
    "\n",
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in xrange(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba725f6-285d-4704-a8a4-8a3f22691075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data (data/test_set.csv) done.\n",
      "#users: 14470, #items: 9396, #ratings: 50000\n",
      "Training MF-BPR with: learning_rate=0.01, regularization=0.0100, factors=10, #epoch=100, batch_size=32.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Run model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m bpr \u001b[38;5;241m=\u001b[39m MFbpr(train, test, num_user, num_item, \n\u001b[0;32m     22\u001b[0m             factors, learning_rate, reg, init_mean, init_stdev)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mbpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxIter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 61\u001b[0m, in \u001b[0;36mMFbpr.build_model\u001b[1;34m(self, maxIter, num_thread, batch_size)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(maxIter):    \n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Each training epoch\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rating\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;66;03m# sample a batch of users, positive samples and negative samples \u001b[39;00m\n\u001b[0;32m     63\u001b[0m         (users, items_pos, items_neg) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch(batch_size)\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;66;03m# perform a batched SGD step\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Load data\n",
    "    dataset = \"data/test_set.csv\"\n",
    "    splitter = \",\"\n",
    "    hold_k_out = 1\n",
    "    train, test, num_user, num_item, num_ratings = LoadRatingFile_HoldKOut(dataset, splitter, hold_k_out)\n",
    "    print(\"Load data (%s) done.\" %(dataset))\n",
    "    print(\"#users: %d, #items: %d, #ratings: %d\" %(num_user, num_item, num_ratings))\n",
    "    \n",
    "    # MFbpr parameters\n",
    "    factors = 10\n",
    "    learning_rate = 0.01\n",
    "    reg = 0.01\n",
    "    init_mean = 0\n",
    "    init_stdev = 0.01\n",
    "    maxIter = 100\n",
    "    num_thread = mp.cpu_count()\n",
    "    \n",
    "    # Run model\n",
    "    bpr = MFbpr(train, test, num_user, num_item, \n",
    "                factors, learning_rate, reg, init_mean, init_stdev)\n",
    "    bpr.build_model(maxIter, num_thread, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
