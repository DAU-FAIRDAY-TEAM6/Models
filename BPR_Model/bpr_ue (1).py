# -*- coding: utf-8 -*-
"""BPR_ue.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GP_sEyQxeCf00-wqNnBNnU85oH-S0Zed
"""

#https://github.com/uestc7d/pytorch-BPR/blob/master/

#!pip install tqdm

import multiprocessing as mp
import argparse
import numpy as np
from numpy import random

import time
#from tqdm import tqdm

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.utils.data import Dataset

import math
import heapq # for retrieval topK
import multiprocessing

class MFbpr(nn.Module):

    def __init__(self, dataset, factors, learning_rate, reg, init_mean, init_stdev):
        '''
        Constructor
        '''
        super(MFbpr, self).__init__()
        self.dataset = dataset
        self.train = dataset.train
        self.test = dataset.test
        self.num_user = dataset.num_user
        self.num_item = dataset.num_item
        self.neg = dataset.neg
        self.factors = factors
        self.learning_rate = learning_rate
        self.reg = reg
        self.init_mean = init_mean
        self.init_stdev = init_stdev

        # user & item latent vectors
        self.U = torch.normal(mean = self.init_mean * torch.ones(self.num_user, self.factors), std = self.init_stdev).requires_grad_()
        self.V = torch.normal(mean = self.init_mean * torch.ones(self.num_item, self.factors), std = self.init_stdev).requires_grad_()

        # optim
        self.mf_optim = optim.Adam([self.U, self.V], lr=self.learning_rate)
        # self.mf_scheduler = optim.lr_scheduler.MultiStepLR(self.mf_optim, [30, 200], 0.1)
        # Each element is the set of items for a user, used for negative sampling
        self.items_of_user = []
        self.num_rating = 0     # number of ratings
        for u in range(len(self.train)):  # xrange를 range로 수정
            self.items_of_user.append(set([]))  # sets 모듈을 사용하는 대신 set을 직접 사용
            for i in range(len(self.train[u])):  # xrange를 range로 수정
                item = self.train[u][i][0]
                self.items_of_user[u].add(item)
                self.num_rating += 1


    def forward(self, u, i, j):
        '''
        Args:
            u: user id. type=int or list.
            i: positive item id. type=int or list.
            j: negative item id. type=int or list.

        Returns:
            y_ui: predicted score between user and positive item.
            y_uj: predicted score between user and negative item.
            loss: BPR loss. It is the opposite of BPR-OPT.
        '''
        y_ui = torch.diag(torch.mm(self.U[u], self.V[i].t()))
        y_uj = torch.diag(torch.mm(self.U[u], self.V[j].t()))
        regularizer = self.reg * (torch.sum(self.U[u] ** 2) + torch.sum(self.V[i] ** 2) + torch.sum(self.V[j] ** 2))
        loss = regularizer - torch.sum(torch.log2(torch.sigmoid(y_ui - y_uj)))
        return y_ui, y_uj, loss

    def build_model(self, maxIter=100, num_thread=4, batch_size=32):
        # dataloader
        data_loader = DataLoader(self.dataset, batch_size=batch_size)

        # Training process
        print("Training MF-BPR with: learning_rate={:.4f}, regularization={:.4f}, factors={}, #epoch={}, batch_size={}.".format(
            self.learning_rate, self.reg, self.factors, maxIter, batch_size))  # 수정된 print 문
        t1 = time.time()
        iter_loss = 0
        for iteration in range(maxIter):  # xrange를 range로 수정
            # self.mf_scheduler.step()
            # Each training epoch
            for s, (users, items_pos, items_neg) in enumerate(data_loader):
                # sample a batch of users, positive samples and negative samples

                # zero grad
                self.mf_optim.zero_grad()
                # forward propagation
                y_ui, y_uj, loss = self.forward(users, items_pos, items_neg)
                iter_loss += loss
                # back propagation
                loss.backward()
                self.mf_optim.step()

            # check performance
            if iteration % 20 == 19:
                t2 = time.time()
                topK = 20
                (hits, ndcgs) = evaluate_model(self, self.test, topK, num_thread)
                # save the hr and ndcg value.
                hr_mean = np.array(hits).mean()
                ndcg_mean = np.array(ndcgs).mean()

                print("Iter={} [{:.1f} s] HitRatio@{} = {:.4f}, NDCG@{} = {:.4f} [{:.1f} s]".format(
                    iteration, (t2-t1) / 20, topK, hr_mean, topK, ndcg_mean, time.time()-t2))  # 수정된 print 문
                t1 = time.time()
                iter_loss = 0


    def predict(self, u, i):
        return np.inner(self.U[u].detach().numpy(), self.V[i].detach().numpy())

    def get_batch(self, batch_size):
        users, pos_items, neg_items = [], [], []
        for i in range(batch_size):  # xrange를 range로 수정
            # sample a user
            u = np.random.randint(0, self.num_user)
            # sample a positive item
            i = self.train[u][np.random.randint(0, len(self.train[u]))][0]
            # sample a negative item
            j = np.random.randint(0, self.num_item)
            while j in self.items_of_user[u]:
                j = np.random.randint(0, self.num_item)
            users.append(u)
            pos_items.append(i)
            neg_items.append(j)
        return (users, pos_items, neg_items)

def LoadRatingFile_HoldKOut(filename, splitter, K):
    """
    Each line of .rating file is: userId(starts from 0), itemId, ratingScore, time
    Each element of train is the [[item1, time1], [item2, time2] of the user, sorted by time
    Each element of test is the [user, item, time] interaction, sorted by time
    """
    train = []
    test = []

    # load ratings into train.
    num_ratings = 0
    num_item = 0
    with open(filename, "r") as f:
        line = f.readline()
        while line != None and line != "":
            arr = line.split(splitter)
            if (len(arr) < 4):
                continue
            user, item, time = int(arr[0]), int(arr[1]), long(arr[3])
            if (len(train) <= user):
                train.append([])
            train[user].append([item, time])
            num_ratings += 1
            num_item = max(item, num_item)
            line = f.readline()
    num_user = len(train)
    num_item = num_item + 1

    # sort ratings of each user by time
    def getTime(item):
        return item[-1];
    for u in range (len(train)):
        train[u] = sorted(train[u], key = getTime)

    # split into train/test
    for u in range (len(train)):
        for k in range(K):
            if (len(train[u]) == 0):
                break
            test.append([u, train[u][-1][0], train[u][-1][1]])
            del train[u][-1]    # delete the last element from train

    # sort the test ratings by time
    test = sorted(test, key = getTime)

    return train, test, num_user, num_item, num_ratings





class Pinterest(Dataset):
    def __init__(self, dir, splitter, K):
        """
        Each line of .rating file is: userId(starts from 0), itemId, ratingScore, time
        Each element of train is the [[item1, time1], [item2, time2] of the user, sorted by time
        Each element of test is the [user, item, time] interaction, sorted by time
        """

        self.train = []

        # load ratings into train.
        self.num_ratings = 0
        self.num_item = 0
        with open(dir+'pos.txt', "r") as f:
            line = f.readline()
            while line != None and line != "":
                arr = line.split(splitter)
                if (len(arr) < 2):
                    continue
                user, item = int(arr[0]), int(arr[1])
                if (len(self.train) <= user):
                    self.train.append([])
                self.train[user].append([item])
                self.num_ratings += 1
                self.num_item = max(item, self.num_item)
                line = f.readline()
        self.num_user = len(self.train)
        self.num_item = self.num_item + 1

        self.test = []
        self.neg = dict()
        # load ratings into test.
        user = 0
        with open(dir+'neg.txt', 'r') as f_neg:
            line = f_neg.readline()
            while line != None and line != '':
                arr = line.split(splitter)
                pos = int(arr[0])
                self.test.append([user, pos])
                self.neg[user] = []
                for neg_i in range(len(arr)):
                    if arr[neg_i] != '\n':
                        self.neg[user].append(int(arr[neg_i]))

                user += 1
                line = f_neg.readline()
        print("#users: %d, #items: %d, #ratings: %d" %(self.num_user, self.num_item, self.num_ratings))


    def __len__(self):
        return self.num_user


    def __getitem__(self, idx):
        u = idx
        i = self.train[u][np.random.randint(0, len(self.train[u]))]
        j = np.random.randint(0, self.num_item)
        while j in self.train[u]:
            j = np.random.randint(0, self.num_item)

        return (u, i, j)

# Global variables that are shared across processes
_model = None
_testRatings = None
_K = None

def evaluate_model(model, testRatings, K, num_thread):
    """
    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation
    Return: score of each test rating.
    """
    global _model
    global _testRatings
    global _K
    _model = model
    _testRatings = testRatings
    _K = K
    num_rating = len(testRatings)

    pool = multiprocessing.Pool(processes=num_thread)
    res = pool.map(eval_one_rating, range(num_rating))
    pool.close()
    pool.join()

    hits = [r[0] for r in res]
    ndcgs = [r[1] for r in res]
#    lp.print_stats()
    return (hits, ndcgs)

def eval_one_rating(idx):
    rating = _testRatings[idx]
    hr = ndcg = 0
    u = rating[0]
    gtItem = rating[1]
    map_item_score = {}

    # Get the score of the test item first
    maxScore = _model.predict(u, gtItem)

    # Early stopping if there are K items larger than maxScore.
    countLarger = 0
    for i in _model.neg[u]:
        early_stop = False
        score = _model.predict(u, i)
        map_item_score[i] = score

        if score > maxScore:
            countLarger += 1
        if countLarger > _K:
            hr = ndcg = 0
            early_stop = True
            break
    if not early_stop:
        ranklist = heapq.nlargest(_K, map_item_score, key=map_item_score.get)
        hr = getHitRatio(ranklist, gtItem)
        ndcg = getNDCG(ranklist, gtItem)

    return (hr, ndcg)

def getHitRatio(ranklist, gtItem):
    for item in ranklist:
        if item == gtItem:
            return 1
    return 0

def getNDCG(ranklist, gtItem):
    for i in range(len(ranklist)):
        item = ranklist[i]
        if item == gtItem:
            return math.log(2) / math.log(i+2)
    return 0

# Commented out IPython magic to ensure Python compatibility.
# %time

def parse_args():
    args = argparse.Namespace()
    args.batch_size = 32
    args.learning_rate = 0.0003
    return args


if __name__ == '__main__':
    args = parse_args()
    # Load data
    dataset = "./data/"
    splitter = " "
    hold_k_out = 1
    pinterest = Pinterest(dataset, splitter, hold_k_out)


    # MFbpr parameters
    factors = 64
    learning_rate = args.learning_rate
    reg = 0.01
    init_mean = 0
    init_stdev = 0.01
    maxIter = 10000
    batch_size = args.batch_size
    num_thread = mp.cpu_count()
    print("#factors: %d, lr: %f, reg: %f, batch_size: %d" % (factors, learning_rate, reg, batch_size))

    # Run model
    bpr = MFbpr(pinterest,
                factors, learning_rate, reg, init_mean, init_stdev)
    bpr.build_model(maxIter, num_thread, batch_size=batch_size)

    # save model
    np.save("out/u"+str(learning_rate)+".npy", bpr.U.detach().numpy())
    np.save("out/v"+str(learning_rate)+".npy", bpr.V.detach().numpy())