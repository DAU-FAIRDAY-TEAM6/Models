{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "LK6gbYguuDtg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gPQbpBq8WKvE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "3a828c22-d0cd-4d85-d602-453451bb85b7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f61726763756>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q torch-scatter~=2.1.0 torch-sparse~=0.6.16 torch-cluster~=1.6.0 torch-spline-conv~=1.2.1 torch-geometric==2.2.0 -f https://data.pyg.org/whl/torch-{torch.__version__}.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mdynamo_config_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/external_utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "!pip install -q torch-scatter~=2.1.0 torch-sparse~=0.6.16 torch-cluster~=1.6.0 torch-spline-conv~=1.2.1 torch-geometric==2.2.0 -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim, Tensor\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn import LGConv"
      ],
      "metadata": {
        "id": "LvrCuPI7ix1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Data"
      ],
      "metadata": {
        "id": "4vk1-SdTuG3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_Data():\n",
        "    df = pd.read_csv('checkins.txt', names=['user_id', 'poi_id', 'latitude', 'longitude', 'city'])\n",
        "    df = df.drop('latitude', axis=1)\n",
        "    df = df.drop('longitude', axis=1)\n",
        "    df = df.drop('city', axis=1)\n",
        "\n",
        "\n",
        "    history_list = []\n",
        "    tmp = []\n",
        "    current_user = None\n",
        "    for index, row in df.iterrows():\n",
        "        # 현재 처리 중인 user_id가 이전과 다르면 새로운 리스트 추가\n",
        "        if row['user_id'] != current_user:\n",
        "            if current_user is not None and len(tmp) >= 10:  # 방문 횟수가 10회 이상인 유저만 추가\n",
        "                random.shuffle(tmp)\n",
        "                history_list.append(tmp)\n",
        "            tmp = [int(row['poi_id'])]  # 새로운 유저의 첫 poi_id를 여기에서 추가\n",
        "            current_user = row['user_id']  # 현재 유저 ID 업데이트\n",
        "        else:\n",
        "            # 현재 user_id의 리스트에 poi_id 추가\n",
        "            tmp.append(int(row['poi_id']))\n",
        "\n",
        "    # 마지막 유저의 데이터 처리\n",
        "    if len(tmp) >= 10:  # 마지막 유저의 리스트 길이 확인\n",
        "        random.shuffle(tmp)\n",
        "        history_list.append(tmp)\n",
        "\n",
        "    #print(\"길이 :\", len(history_list))\n",
        "    #print(history_list[:1])\n",
        "    return history_list"
      ],
      "metadata": {
        "id": "ZiBoPH_qWoq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Get Edge Index from history list\n",
        "\"\"\"\n",
        "def split_train_val_test(history_list):\n",
        "    train_set = []\n",
        "    validation_set = []\n",
        "    test_set = []\n",
        "\n",
        "    for visits in history_list:\n",
        "        # 7:1.5:1.5 비율로 나누기 위한 인덱스 계산\n",
        "        train_end = int(len(visits) * 0.7)\n",
        "        validation_end = train_end + int(len(visits) * 0.15)\n",
        "\n",
        "        # 실제 데이터 분할\n",
        "        train, validation, test = visits[:train_end], visits[train_end:validation_end], visits[validation_end:]\n",
        "\n",
        "        # 각 셋에 추가\n",
        "        train_set.append(train)\n",
        "        validation_set.append(validation)\n",
        "        test_set.append(test)\n",
        "    #print((train_set[0], validation_set[0], test_set[0]))\n",
        "    return train_set, validation_set, test_set\n",
        "\n",
        "def Get_EdgeIndices(history_list, num_users, num_pois):\n",
        "    num_total = num_users + num_pois\n",
        "\n",
        "    # Build the adjacency matrix based on user ratings\n",
        "    user_ids = []\n",
        "    poi_ids = []\n",
        "    for user_idx, pois in enumerate(history_list):\n",
        "        user_ids.extend([user_idx] * len(pois))  # 유저 인덱스를 반복하여 추가\n",
        "        poi_ids.extend(pois)  # 해당 유저가 방문한 POI 아이디 추가\n",
        "\n",
        "    user_ids_tensor = torch.LongTensor(user_ids)\n",
        "    poi_ids_tensor = torch.LongTensor(poi_ids)\n",
        "    edge_index = torch.stack((user_ids_tensor, poi_ids_tensor))\n",
        "\n",
        "    #print(len(poi_ids), edge_index[:5])\n",
        "    return edge_index"
      ],
      "metadata": {
        "id": "qMzCKCR1YOqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGCN"
      ],
      "metadata": {
        "id": "u2OKzH2onV0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "iijnyH7Rx0W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCN(nn.Module):\n",
        "    def __init__(self, num_users, num_items, num_layers=4, dim_h=32):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.num_layers = num_layers\n",
        "        self.emb_users = nn.Embedding(num_embeddings=self.num_users, embedding_dim=dim_h)\n",
        "        self.emb_items = nn.Embedding(num_embeddings=self.num_items, embedding_dim=dim_h)\n",
        "\n",
        "        self.convs = nn.ModuleList(LGConv() for _ in range(num_layers))\n",
        "\n",
        "        # 임베딩 초기화\n",
        "        nn.init.normal_(self.emb_users.weight, std=0.01)\n",
        "        nn.init.normal_(self.emb_items.weight, std=0.01)\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        # 유저 임베딩 아래에 아이템 임베딩을 이어붙여 한번에 계산\n",
        "        emb = torch.cat([self.emb_users.weight, self.emb_items.weight])\n",
        "        embs = [emb] # emb shape : (users + items) x emb\n",
        "\n",
        "        for conv in self.convs:\n",
        "            emb = conv(x=emb, edge_index=edge_index)\n",
        "            embs.append(emb) # 최종적으로 초기 emb 1개 + 각각의 conv layer를 통과한 emb 3개\n",
        "\n",
        "        # stack으로 만든 (users + items) x 4 x emb 행렬에서 1번째 dim(4)를 기준으로 평균을 낸 (users + items) x emb 생성\n",
        "        emb_final = 1/(self.num_layers+1) * torch.mean(torch.stack(embs, dim=1), dim=1)\n",
        "\n",
        "        emb_users_final, emb_items_final = torch.split(emb_final, [self.num_users, self.num_items])\n",
        "        # .weight를 붙여 초기 상태의 임베딩도 반환함\n",
        "        return emb_users_final, self.emb_users.weight, emb_items_final, self.emb_items.weight"
      ],
      "metadata": {
        "id": "Qwvf6JdceFUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 미니배치 그래프 정보(ng_sampling 포함)를 불러옴\n",
        "def sample_mini_batch(edge_index, BATCH_SIZE = 1024):\n",
        "    # BATCH_SIZE만큼의 랜덤 엣지 인덱스를 가져옴\n",
        "    index = np.random.choice(range(edge_index.shape[1]), size=BATCH_SIZE)\n",
        "\n",
        "    # 주어진 positive edge에 대해 negative edge 생성하고 추가함\n",
        "    edge_index = structured_negative_sampling(edge_index)\n",
        "    edge_index = torch.stack(edge_index, dim=0)\n",
        "\n",
        "    user_index = edge_index[0, index]\n",
        "    pos_item_index = edge_index[1, index]\n",
        "    neg_item_index = edge_index[2, index]\n",
        "\n",
        "    return user_index, pos_item_index, neg_item_index\n",
        "\n",
        "# Loss 함수 구현\n",
        "def bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items, LAMBDA = 1e-6):\n",
        "    reg_loss = LAMBDA * (emb_users.norm().pow(2) +\n",
        "                        emb_pos_items.norm().pow(2) +\n",
        "                        emb_neg_items.norm().pow(2))\n",
        "\n",
        "    pos_ratings = torch.mul(emb_users_final, emb_pos_items_final).sum(dim=-1)\n",
        "    neg_ratings = torch.mul(emb_users_final, emb_neg_items_final).sum(dim=-1)\n",
        "\n",
        "    #bpr_loss = torch.mean(torch.nn.functional.softplus(pos_ratings - neg_ratings))\n",
        "    bpr_loss = torch.mean(torch.nn.functional.logsigmoid(pos_ratings - neg_ratings))\n",
        "\n",
        "    # return에 (-)를 붙였기 때문에 최적화 과정에서 loss가 작아지기 위해선 pos-neg_ratings가 커져야함\n",
        "    # -> pos rating이 커지고, neg rating이 작아지는 방향으로 학습\n",
        "    return -bpr_loss + reg_loss\n",
        "\n",
        "# 각 사용자가 상호작용한 아이템의 리스트를 만들어내는 함수\n",
        "def get_user_items(edge_index):\n",
        "    user_items = dict()\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        if user not in user_items:\n",
        "            user_items[user] = []\n",
        "        user_items[user].append(item)\n",
        "    return user_items\n"
      ],
      "metadata": {
        "id": "0sKIOSRnol40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test & Evaluation Define"
      ],
      "metadata": {
        "id": "t-LJoogWqkzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_recall_at_k(items_ground_truth, items_predicted):\n",
        "    num_correct_pred = np.sum(items_predicted, axis=1)\n",
        "    num_total_pred = np.array([len(items_ground_truth[i]) for i in range(len(items_ground_truth))])\n",
        "\n",
        "    recall = np.mean(num_correct_pred / num_total_pred)\n",
        "\n",
        "    return recall\n",
        "\n",
        "def compute_ndcg_at_k(items_ground_truth, items_predicted):\n",
        "    # items_ground_truth: 실제 선호 리스트, items_predicted : 추천 아이템 리스트\n",
        "\n",
        "    # 실제 선호 아이템에 대한 행렬 생성(선호 : 1, 아니면 : 0), relevance 역할\n",
        "    test_matrix = np.zeros((len(items_predicted), K))\n",
        "    for i, items in enumerate(items_ground_truth):\n",
        "        length = min(len(items), K)\n",
        "        test_matrix[i, :length] = 1\n",
        "\n",
        "    # IDCG 계산\n",
        "    max_r = test_matrix # 이상적인 상황에서의 행렬\n",
        "    idcg = np.sum(max_r * 1. / np.log2(np.arange(2, K + 2)), axis=1) # 사용자별로 이상적인 상황에서의 DCG 값 계산\n",
        "    dcg = items_predicted * (1. / np.log2(np.arange(2, K + 2))) # DCG 값 계산\n",
        "    dcg = np.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.] = 1. # idcg가 0인경우, 0으로 나누는것을 방지\n",
        "    ndcg = dcg / idcg # NDCG 계산\n",
        "    ndcg[np.isnan(ndcg)] = 0. # NAN값은 0으로 처리\n",
        "\n",
        "    return np.mean(ndcg)\n",
        "\n",
        "# wrapper function to get evaluation metrics\n",
        "def get_metrics(model, edge_index, exclude_edge_indices):\n",
        "    # user_num x item_num, 사용자별 아이템 평가점수 행렬 계산\n",
        "    ratings = torch.matmul(model.emb_users.weight, model.emb_items.weight.T)\n",
        "\n",
        "    # 평가 과정에서 제외할 user-item 쌍을 식별, 매우 낮은값(-1024)로 설정하여 추천에서 제외\n",
        "    for exclude_edge_index in exclude_edge_indices:\n",
        "        user_pos_items = get_user_items(exclude_edge_index)\n",
        "        exclude_users = []\n",
        "        exclude_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            exclude_users.extend([user] * len(items))\n",
        "            exclude_items.extend(items)\n",
        "        ratings[exclude_users, exclude_items] = -1024\n",
        "\n",
        "    # get the top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(ratings, k=K)\n",
        "\n",
        "    # get all unique users in evaluated split\n",
        "    users = edge_index[0].unique()\n",
        "\n",
        "    test_user_pos_items = get_user_items(edge_index)\n",
        "\n",
        "    # convert test user pos items dictionary into a list\n",
        "    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "    # determine the correctness of topk predictions\n",
        "    items_predicted = []\n",
        "    for user in users:\n",
        "        ground_truth_items = test_user_pos_items[user.item()]\n",
        "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
        "        items_predicted.append(label)\n",
        "\n",
        "    recall = compute_recall_at_k(test_user_pos_items_list, items_predicted)\n",
        "    ndcg = compute_ndcg_at_k(test_user_pos_items_list, items_predicted)\n",
        "\n",
        "    return recall, ndcg"
      ],
      "metadata": {
        "id": "IMAiC4eGqnmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrapper function to evaluate model\n",
        "def test(model, edge_index, exclude_edge_indices): # train에서 사용한 edge_index들은 제외\n",
        "    emb_users_final, emb_users, emb_items_final, emb_items = model.forward(edge_index)\n",
        "    user_indices, pos_item_indices, neg_item_indices = structured_negative_sampling(edge_index, contains_neg_self_loops=False)\n",
        "\n",
        "    emb_users_final, emb_users = emb_users_final[user_indices], emb_users[user_indices]\n",
        "\n",
        "    emb_pos_items_final, emb_pos_items = emb_items_final[pos_item_indices], emb_items[pos_item_indices]\n",
        "    emb_neg_items_final, emb_neg_items = emb_items_final[neg_item_indices], emb_items[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items).item()\n",
        "\n",
        "    recall, ndcg = get_metrics(model, edge_index, exclude_edge_indices)\n",
        "\n",
        "    return loss, recall, ndcg"
      ],
      "metadata": {
        "id": "Pj4Qqs08qm56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "cU-oQb35pIMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_POIS = 14586\n",
        "K = 20\n",
        "LAMBDA = 1e-6\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "history_list = get_Data()\n",
        "num_users = len(history_list)\n",
        "\n",
        "train_set, validation_set, test_set = split_train_val_test(history_list)\n",
        "\n",
        "edge_index = Get_EdgeIndices(history_list, num_users, NUM_POIS)\n",
        "train_edge_index = Get_EdgeIndices(train_set, num_users, NUM_POIS)\n",
        "val_edge_index = Get_EdgeIndices(validation_set, num_users, NUM_POIS)\n",
        "test_edge_index = Get_EdgeIndices(test_set, num_users, NUM_POIS)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "QG_4hbrwpH1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "n_batch = int(len(train_set)/BATCH_SIZE)\n",
        "\n",
        "\n",
        "model = LightGCN(num_users, NUM_POIS)\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "for epoch in range(21):\n",
        "    model.train()\n",
        "\n",
        "    for _ in range(n_batch):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        emb_users_final, emb_users, emb_items_final, emb_items = model.forward(train_edge_index) # 전체 유저의 임베딩을 얻음\n",
        "        user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(train_edge_index)\n",
        "        # train시킨 edge_index에 포함하는 임베딩만 추출(BatchSize(1024)개)\n",
        "        emb_users_final, emb_users = emb_users_final[user_indices], emb_users[user_indices]\n",
        "\n",
        "        # 미니배치의 pos,neg 아이템의 임베딩을 추출함\n",
        "        emb_pos_items_final, emb_pos_items = emb_items_final[pos_item_indices], emb_items[pos_item_indices]\n",
        "        emb_neg_items_final, emb_neg_items = emb_items_final[neg_item_indices], emb_items[neg_item_indices]\n",
        "\n",
        "        train_loss = bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items)\n",
        "\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        model.eval()\n",
        "        val_loss, recall, ndcg = test(model, val_edge_index, [train_edge_index])\n",
        "        print(f\"Epoch {epoch} | Train loss: {train_loss.item():.5f} | Val loss: {val_loss:.5f} | Val recall@{K}: {recall:.5f} | Val ndcg@{K}: {ndcg:.5f}\")\n",
        "\n",
        "test_loss, test_recall, test_ndcg = test(model, test_edge_index.to(device), [train_edge_index, val_edge_index])\n",
        "print(f\"Test loss: {test_loss:.5f} | Test recall@{K}: {test_recall:.5f} | Test ndcg@{K}: {test_ndcg:.5f}\")"
      ],
      "metadata": {
        "id": "ga2nHWRDq65x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test & Recommend"
      ],
      "metadata": {
        "id": "lalYNurVvC9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bookid_title = pd.Series(books['Title'].values, index=books.ISBN).to_dict()\n",
        "bookid_author = pd.Series(books['Author'].values, index=books.ISBN).to_dict()\n",
        "user_pos_items = get_user_items(edge_index)\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "def recommend(user_id, num_recs):\n",
        "    # 추천받고자 하는 user_id, 추천 받을 개수를 받아옴\n",
        "    user = user_mapping[user_id]\n",
        "    emb_user = model.emb_users.weight[user] # 해당 유저의 임베딩을 가져옴\n",
        "    ratings = model.emb_items.weight @ emb_user # 유저 임베딩으로 아이템별 점수 측정\n",
        "\n",
        "    values, indices = torch.topk(ratings, k=100) # 점수가 높은 아이템 100개 추출\n",
        "\n",
        "    # 100개 중 user가 상호작용한 book들만 ids에 저장,\n",
        "    ids = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
        "    # ids에 있는 책들의 ISBN을 가져옴\n",
        "    item_isbns = [list(item_mapping.keys())[list(item_mapping.values()).index(book)] for book in ids]\n",
        "    # 위에서 가져온 ISBN으로 제목과 저자를 가져옴\n",
        "    titles = [bookid_title[id] for id in item_isbns]\n",
        "    authors = [bookid_author[id] for id in item_isbns]\n",
        "\n",
        "    print(f'Favorite books from user n°{user_id}:')\n",
        "    for i in range(len(item_isbns)):\n",
        "        print(f'- {titles[i]}, by {authors[i]}')\n",
        "\n",
        "    # # 100개 중 user가 상호작용하지 않은 book들만 ids에 저장, 이후 위와 동일\n",
        "    ids = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
        "    item_isbns = [list(item_mapping.keys())[list(item_mapping.values()).index(book)] for book in ids]\n",
        "    titles = [bookid_title[id] for id in item_isbns]\n",
        "    authors = [bookid_author[id] for id in item_isbns]\n",
        "\n",
        "    print(f'\\nRecommended books for user n°{user_id}')\n",
        "    for i in range(num_recs):\n",
        "        print(f'- {titles[i]}, by {authors[i]}')\n",
        "\n",
        "\n",
        "    # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "    # fig, axs = plt.subplots(1, num_recs, figsize=(20,6))\n",
        "    # fig.patch.set_alpha(0)\n",
        "    # for i, title in enumerate(titles):\n",
        "    #     # 책의 이미지 출력\n",
        "    #     url = books.loc[books['Title'] == title]['Image-URL-L'][:1].values[0]\n",
        "    #     img = Image.open(requests.get(url, stream=True, headers=headers).raw)\n",
        "    #     rating = df.loc[df['ISBN'] == books.loc[books['Title'] == title]['ISBN'][:1].values[0]]['Rating'].mean()\n",
        "    #     axs[i].axis(\"off\")\n",
        "    #     axs[i].imshow(img)\n",
        "    #     axs[i].set_title(f'{rating:.1f}/10', y=-0.1, fontsize=18)\n",
        "\n",
        "#print(user_mapping)\n",
        "\n",
        "recommend(114611, 5)"
      ],
      "metadata": {
        "id": "qP-ryNbxvIPC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}